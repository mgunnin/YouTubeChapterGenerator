[1.8 - 5.339] good morning everybody David Shapiro

[3.959 - 8.040000000000001] here with another video

[5.339 - 11.88] so today's video is going to be about

[8.04 - 15.178999999999998] the salvation fantasy or the Dark Side

[11.88 - 17.1] of utopian narratives and so before I

[15.179 - 18.359] even get started a lot of you might be

[17.1 - 20.039] saying well but Dave you're the one

[18.359 - 22.859] who's constantly talking about Utopia

[20.039 - 25.5] which is exactly why I Define Utopia in

[22.859 - 27.840000000000003] very very concrete measurable terms such

[25.5 - 30.72] as standard of living individual liberty

[27.84 - 33.48] and social Mobility by defining Utopia

[30.72 - 36.239] in those very concrete measurable terms

[33.48 - 38.339999999999996] I deliberately try to de-identify it

[36.239 - 40.199999999999996] with these other more salvation fantasy

[38.34 - 42.84] narratives so let's unpack what a

[40.2 - 44.879000000000005] Salvation fantasy is but before we do

[42.84 - 48.239000000000004] that just a quick plug for my patreon

[44.879 - 51.539] everything I do is uh provided for free

[48.239 - 54.18] no ads no friction including my videos

[51.539 - 57.0] and all my code and all my research but

[54.18 - 59.34] I am 100 dependent upon Grassroots

[57.0 - 61.379] support such as from you so if you like

[59.34 - 63.0] what I do and want to keep me in

[61.379 - 65.64] business please go ahead and jump over

[63.0 - 67.28] and support me on patreon okay well all

[65.64 - 71.88] that back to the show

[67.28 - 73.619] so technology fundamentally is by and

[71.88 - 76.56] large a good thing obviously we keep

[73.619 - 78.9] doing it despite the double-edged nature

[76.56 - 80.7] of Technology it has a lot of benefits

[78.9 - 82.74000000000001] health and Medicine communication

[80.7 - 84.119] transportation agriculture and energy

[82.74 - 86.1] industry

[84.119 - 88.259] it has solved a tremendous amount of

[86.1 - 91.14] problems it is generally a foregone

[88.259 - 93.24] conclusion that technology is good for

[91.14 - 96.0] the human race and that progress that

[93.24 - 98.64] technological progress is generally a

[96.0 - 101.7] good thing but one thing that we need to

[98.64 - 103.979] be aware of is that it's not a Panacea

[101.7 - 106.259] it does it's not a cure-all it cannot

[103.979 - 109.38] solve all problems and in fact

[106.259 - 111.6] technology often introduces new problems

[109.38 - 114.36] not the least of which is climate change

[111.6 - 116.46] driven by the technology to extract and

[114.36 - 118.74] use more fossil fuels just as a prime

[116.46 - 121.079] example from the Industrial Revolution

[118.74 - 123.72] and then in the information age social

[121.079 - 126.65899999999999] media social media was supposed to bring

[123.72 - 129.3] us all together but in in fact it has

[126.659 - 133.09900000000002] eroded democracy and proved to be a very

[129.3 - 136.08] divisive force uh in in society and not

[133.099 - 138.23899999999998] furthermore it increases anxiety and

[136.08 - 140.9] depression for people that use it so

[138.239 - 145.379] social media is something that is a uh

[140.9 - 148.37900000000002] in my opinion social media is uh if we

[145.379 - 149.51999999999998] could uninvent it we probably should

[148.379 - 152.64] um okay

[149.52 - 154.56] now what is a Salvation fantasy I'll

[152.64 - 156.599] just read you the definition salvation

[154.56 - 158.81900000000002] fantasy refers to the deep-seated human

[156.599 - 162.11999999999998] desire or belief in a transformational

[158.819 - 164.16] event entity or breakthrough that will

[162.12 - 166.739] ultimately solve all of one's problems

[164.16 - 169.5] eradicating suffering and lead to an

[166.739 - 171.239] ideal state of existence this com this

[169.5 - 173.54] concept encompasses a wide array of

[171.239 - 175.68] contexts including but not limited to

[173.54 - 178.14] religious narratives many religions

[175.68 - 180.06] around the world have a savior or a

[178.14 - 181.98] messiah narrative and in fact this is

[180.06 - 183.84] what Frank Herbert did with Dune the

[181.98 - 186.48] entire point was to be skeptical of

[183.84 - 188.28] Savior narratives and Messiahs or

[186.48 - 191.159] Deliverance to some kind of paradise or

[188.28 - 192.48] afterlife uh again this is a global

[191.159 - 194.519] thing I know that I used Christian

[192.48 - 196.61999999999998] iconography but this is certainly not

[194.519 - 199.14000000000001] limited to Christianity fictional

[196.62 - 201.42000000000002] narratives Hero Stories great Journeys

[199.14 - 204.11999999999998] the promised lands usually rescue

[201.42 - 206.879] narratives and then techno optimism so

[204.12 - 208.37900000000002] for instance uh techno optimism is the

[206.879 - 210.78] simple belief that technology is a

[208.379 - 213.599] Panacea to everything and that it will

[210.78 - 215.94] technology will inevitably or likely

[213.599 - 217.61999999999998] result in Utopia and then finally mental

[215.94 - 220.019] health so the the idea of Salvation

[217.62 - 222.78] fantasy actually comes from mental

[220.019 - 226.739] health so for people that have survived

[222.78 - 229.26] uh severe traumas or cope with severe

[226.739 - 231.0] depression or other mental health issues

[229.26 - 233.57999999999998] there's often what's called a Salvation

[231.0 - 236.76] fantasy which is the idea that if you

[233.58 - 238.68] can just do one more thing or just solve

[236.76 - 241.44] one problem then suddenly you'll be

[238.68 - 243.54000000000002] delivered from all of your suffering uh

[241.44 - 246.06] which unfortunately mental illness is

[243.54 - 248.459] not that easy to recover from neither is

[246.06 - 250.5] uh trauma and intergenerational Trauma

[248.459 - 252.239] and so on and so forth but the idea is

[250.5 - 254.76] that there is this hope for the future

[252.239 - 257.76] and this is critical salvation fantasies

[254.76 - 260.28] are about hope it's about saying okay

[257.76 - 261.71999999999997] I'm hoping for the alleviation of

[260.28 - 263.82] suffering in the future and so I'm going

[261.72 - 265.8] to cling to this idea that one day

[263.82 - 268.02] things will be better

[265.8 - 271.199] uh but one thing to keep in mind is that

[268.02 - 273.59999999999997] it is often an external uh event or

[271.199 - 276.0] person so basically something else will

[273.6 - 277.74] change in my outside world that will

[276.0 - 280.68] then make my life infinitely better

[277.74 - 282.12] whether it you know in the case of uh

[280.68 - 284.40000000000003] religious narratives there's you know

[282.12 - 286.74] the the end of the uh what is it the

[284.4 - 288.35999999999996] Rapture or whatever that some uh some

[286.74 - 291.419] versions of Christianity believe in and

[288.36 - 292.68] even then not all not all uh divisions

[291.419 - 295.32] of Christianity who believe in the

[292.68 - 297.84000000000003] Rapture uh fictional narratives the idea

[295.32 - 299.699] that you know uh the hero goes and

[297.84 - 301.79999999999995] seizes the magic sword you know Frodo

[299.699 - 303.6] throws the ring into the uh into the

[301.8 - 305.28000000000003] volcano at Mountain doom and then

[303.6 - 306.36] suddenly the war is over and life is

[305.28 - 307.73999999999995] better

[306.36 - 310.56] um you know everyone is delivered from

[307.74 - 313.08] the orc hordes uh techno optimism the

[310.56 - 315.12] idea that you know full dive VR and

[313.08 - 317.03999999999996] genetic engineering and post-humanism

[315.12 - 320.1] and transhumanism will all result in a

[317.04 - 321.90000000000003] better future not necessarily true uh

[320.1 - 324.47900000000004] and likewise you know we see this with

[321.9 - 327.67999999999995] uh mental health today with the uh the

[324.479 - 331.25899999999996] meteoric rise of of

[327.68 - 332.46] legalizing of marijuana and the upcoming

[331.259 - 334.91900000000004] all the research being done in the

[332.46 - 337.62] psychedelics the idea is that these

[334.919 - 339.479] natural-based plant medicines will uh

[337.62 - 342.419] you know basically save Society from

[339.479 - 344.15999999999997] from mental health and to be fair uh

[342.419 - 347.039] there is plenty of evidence that both of

[344.16 - 349.199] those substances when used correctly can

[347.039 - 351.539] greatly reduce suffering for many many

[349.199 - 353.88] people but that being said life is still

[351.539 - 355.199] hard even if you get rid of those

[353.88 - 357.3] problems life is still hard and that's

[355.199 - 359.639] not to diminish the value of technology

[357.3 - 362.52000000000004] and these breakthroughs to help

[359.639 - 364.68] but the idea is that even if they help

[362.52 - 366.78] they will not get you to an idealized

[364.68 - 369.6] state of existence so that is the

[366.78 - 371.4] context of what a Salvation fantasy is

[369.6 - 374.28000000000003] so let's talk about utopian narratives

[371.4 - 375.84] as a type of Salvation fantasy so in the

[374.28 - 379.08] in the grand scheme of things salvation

[375.84 - 381.539] fantasies are exist throughout the world

[379.08 - 385.919] and throughout history they have existed

[381.539 - 388.09999999999997] for basically in all of humanity utopian

[385.919 - 391.5] narratives are also nothing really new

[388.1 - 393.36] uh from Plato's Republic to you know

[391.5 - 397.319] myths of Shangri-La and everything else

[393.36 - 399.3] we all have this idea of like hey you

[397.319 - 401.1] know if you get to heaven where there's

[399.3 - 404.039] going to be nothing wrong and everything

[401.1 - 406.68] is bliss all the time that is the carrot

[404.039 - 408.36] that is the lure the hope that one day

[406.68 - 411.06] things will be better

[408.36 - 413.759] so there's a few uh characteristics of

[411.06 - 415.319] utopian narratives so post-scarcity and

[413.759 - 418.74] hyperabundance this is something that I

[415.319 - 420.12] talk about a lot uh and so basically the

[418.74 - 421.74] reason that I'm bringing this up is I

[420.12 - 424.62] want to temper your expectations that

[421.74 - 427.02] while I talk about these things uh I

[424.62 - 429.539] also want to urge caution and not really

[427.02 - 431.81899999999996] focus on this is going to be a Salvation

[429.539 - 434.639] this is a solution to some problems but

[431.819 - 436.97900000000004] it's not going to solve all problems

[434.639 - 439.86] Global Peace and Harmony is another

[436.979 - 441.65999999999997] component of Salvation fantasies the

[439.86 - 445.08000000000004] idea that we will have the cessation of

[441.66 - 447.3] all conflict is often part of of the

[445.08 - 448.919] idea you see this more in solar Punk

[447.3 - 450.36] narratives where the idea is like oh get

[448.919 - 452.81899999999996] rid of the police state get rid of all

[450.36 - 454.139] military everyone lives in a hunky-dory

[452.819 - 456.47900000000004] life

[454.139 - 458.28000000000003] um this is also true of anarchist

[456.479 - 460.08] fantasies and libertarian fantasies

[458.28 - 462.11999999999995] where the ideas like get rid of the

[460.08 - 464.28] state you don't need it but this

[462.12 - 467.4] presupposes that you know you won't need

[464.28 - 468.71999999999997] police forces and uh militaries and that

[467.4 - 470.81899999999996] sort of thing that you won't need any

[468.72 - 473.46000000000004] sort of protection or control or

[470.819 - 476.639] application of force total equality and

[473.46 - 480.35999999999996] total freedom uh so again the idea that

[476.639 - 483.72] a Utopia or in order to achieve a Utopia

[480.36 - 485.28000000000003] then everyone will be equal forever and

[483.72 - 487.86] that everyone will be completely free

[485.28 - 490.44] forever not saying that these are bad

[487.86 - 491.819] ideals to work towards but the idea is

[490.44 - 494.539] that if you put the cart before the

[491.819 - 496.74] horse it's not going to to go well

[494.539 - 499.199] because one you might just be

[496.74 - 501.78000000000003] disappointed right when reality doesn't

[499.199 - 504.3] meet expectations but also you know what

[501.78 - 506.21999999999997] they say is that uh the path to hell is

[504.3 - 508.68] paved with good intentions

[506.22 - 510.12] and then longevity and augmentation this

[508.68 - 512.399] goes back to transhumanism and

[510.12 - 514.08] post-humanism the idea that a medical

[512.399 - 515.76] breakthrough will alleviate all of your

[514.08 - 517.5] suffering and to be fair this is

[515.76 - 519.24] something that I hope for

[517.5 - 520.56] um I and many other people struggle with

[519.24 - 523.14] chronic health conditions which it's

[520.56 - 525.3599999999999] like oh man I would love it if there was

[523.14 - 527.76] a pill or an injection or something that

[525.36 - 529.5600000000001] would make my life physically more

[527.76 - 532.019] comfortable hopefully we'll get there

[529.56 - 534.779] but even if that happens there's still a

[532.019 - 537.48] lot there's still uh uh difficulties in

[534.779 - 539.58] life that we'll talk about more but I

[537.48 - 542.04] just wanted to just kind of unpack what

[539.58 - 545.58] a utopian narrative is

[542.04 - 548.5799999999999] now the converse to that is dystopian

[545.58 - 551.0400000000001] narratives and so we have lots and lots

[548.58 - 553.86] of dystopian narratives uh you know the

[551.04 - 556.1999999999999] end of days uh eschatological myths like

[553.86 - 558.54] Ragnarok Armageddon uh this sort of

[556.2 - 560.22] thing there's uh all the antediluvian

[558.54 - 562.0799999999999] myths there's the Bronze Age collapse

[560.22 - 564.839] and all the myths and plays that were

[562.08 - 566.519] created about the Bronze Age collapse so

[564.839 - 568.74] for those that are not history nerds

[566.519 - 571.68] like I and my wife are the Bronze Age

[568.74 - 576.3] collapse was basically uh about 3 200

[571.68 - 579.0] years ago or around uh 1200 BCE and it

[576.3 - 582.56] was a breakdown of the trade and

[579.0 - 585.0] economies all around the Mediterranean

[582.56 - 587.88] particularly the region between Egypt

[585.0 - 591.48] and Greece uh so one of the one of the

[587.88 - 593.64] causes was uh volcanic eruptions another

[591.48 - 597.48] was the breakdown of access to things

[593.64 - 601.14] like tin which harmed their ability to

[597.48 - 603.12] to even make uh bronze tools which then

[601.14 - 605.3389999999999] harmed Agri agriculture there was a few

[603.12 - 607.2] droughts and other famines that happened

[605.339 - 608.94] and so basically what happened for the

[607.2 - 610.5] Bronze Age collapse is that society as

[608.94 - 613.6800000000001] everyone knew it came completely

[610.5 - 616.14] unraveled and you entered into like a

[613.68 - 619.5] Mediterranean Dark Ages that took about

[616.14 - 622.74] 600 to 800 years to recover from but the

[619.5 - 624.779] wars and raiding and pillaging and the

[622.74 - 626.399] starvation that happened was so

[624.779 - 628.98] traumatic that they kept and told

[626.399 - 630.6] stories about it and they kept telling

[628.98 - 632.94] those stories to keep the memory of the

[630.6 - 635.0400000000001] Bronze Age collapse alive for a thousand

[632.94 - 636.7790000000001] years until they could write about it

[635.04 - 639.0] again because literally writing was lost

[636.779 - 640.4399999999999] for a while that's how bad the Bronze

[639.0 - 642.959] Age collapse was that's why we can't

[640.44 - 645.1800000000001] read linear a and Linear B or they're

[642.959 - 647.279] not complete

[645.18 - 649.7399999999999] um and so dystopian narratives or

[647.279 - 652.32] collapse narratives or apocalyptic

[649.74 - 654.42] narratives these are the ways that we

[652.32 - 655.98] make sense of the world

[654.42 - 659.3389999999999] um they're also about warnings in memory

[655.98 - 661.8000000000001] like I said and coping with trauma so in

[659.339 - 663.839] the 20th century we had World War one

[661.8 - 666.54] and World War II and lots of other

[663.839 - 668.1] conflicts there is a reason that there

[666.54 - 670.3199999999999] have been more movies made about World

[668.1 - 673.14] War II than any other single event in

[670.32 - 675.36] all of history this is a human instinct

[673.14 - 678.0] to tell stories about traumatic events

[675.36 - 681.48] to keep that memory alive and to warn

[678.0 - 683.16] people don't do this again now dystopian

[681.48 - 685.38] narratives also project into the future

[683.16 - 688.88] they look back as a way of of keeping

[685.38 - 692.76] memory and and telling stories uh to to

[688.88 - 694.32] transmit lessons across the ages but we

[692.76 - 696.12] also look forward and this is where

[694.32 - 698.4590000000001] cyberpunk narratives come in where it's

[696.12 - 700.26] like hey let's look at the failures of

[698.459 - 702.3] of Technology let's look at the misuse

[700.26 - 705.24] of Technology the failures of democracy

[702.3 - 707.459] and the flaws of capitalism and let's

[705.24 - 709.5600000000001] project that into the future to warn

[707.459 - 711.899] ourselves about what's going wrong

[709.56 - 713.459] sorry I've meant to advance the slide so

[711.899 - 714.959] this is the Dark Side of technology and

[713.459 - 717.7199999999999] that is literally the purpose of

[714.959 - 720.5999999999999] cyberpunk that is why it resonates with

[717.72 - 723.72] us from an evolutionary and unconscious

[720.6 - 726.72] level is that it basically takes all the

[723.72 - 728.88] unconscious fears that we have and puts

[726.72 - 731.1] them on the screen in front of you so

[728.88 - 733.26] that you can talk about it that is why

[731.1 - 736.26] we keep talking about movies like iRobot

[733.26 - 738.48] and the Matrix and Terminator is because

[736.26 - 741.779] those are warnings saying if we don't

[738.48 - 743.399] fix it this is a possibility so all

[741.779 - 744.959] these epic movies that we have like

[743.399 - 747.839] Terminator and the Matrix and stuff

[744.959 - 749.279] these are modern myths this is these are

[747.839 - 751.98] the stories that we tell ourselves to

[749.279 - 753.8389999999999] make sense of the problems that we see

[751.98 - 756.66] and it's also a way that we can come to

[753.839 - 758.94] cultural consensus about about those

[756.66 - 761.519] problems and say hey let's avoid that

[758.94 - 763.2600000000001] let's not go down the dark path and so

[761.519 - 764.76] some of the some of the problems of

[763.26 - 767.399] technology I already mentioned social

[764.76 - 769.019] media a big contributor to mental

[767.399 - 772.079] illness and has also eroded the

[769.019 - 774.24] institutions of democracy uh existential

[772.079 - 776.0999999999999] threats created by technology such as uh

[774.24 - 778.8] biological weapons nuclear weapons and

[776.1 - 780.6] now ai so we just keep stacking on

[778.8 - 782.2199999999999] existential threats to humanity with

[780.6 - 784.139] more technology

[782.22 - 786.1800000000001] excuse me so technology is not

[784.139 - 789.54] universally good it is a double-edged

[786.18 - 792.4799999999999] sword displacement and exploitation uh

[789.54 - 794.6999999999999] jobs poverty globalism has has some

[792.48 - 796.9200000000001] drawbacks it has some Advan some

[794.7 - 799.0790000000001] benefits as well military you know

[796.92 - 801.779] building more weapons bigger weapons

[799.079 - 803.279] smarter weapons autonomous weapons these

[801.779 - 804.72] are not necessarily the uses of

[803.279 - 807.48] technology that we would have preferred

[804.72 - 810.0600000000001] to see uh you know when Tesla and

[807.48 - 812.1] Marconi invented the radio uh I'm not

[810.06 - 814.26] sure that they could have foreseen uh

[812.1 - 816.1800000000001] the use of radio technology to remotely

[814.26 - 817.8] control drones to drop bombs Halfway

[816.18 - 819.3599999999999] Around the World

[817.8 - 821.579] and then finally surveillance and

[819.36 - 823.26] manipulation such as the Cambridge

[821.579 - 826.26] analytica Scandal and the social credit

[823.26 - 828.959] system in China these again are the dark

[826.26 - 830.8199999999999] side uses of technology and so one thing

[828.959 - 833.0999999999999] that it's that is critical to keep in

[830.82 - 835.2] mind at all times is that all

[833.1 - 839.519] Technologies are dual use and that all

[835.2 - 841.74] Technologies are uh can it's how you use

[839.519 - 843.54] it right technology is not intrinsically

[841.74 - 845.88] good or evil it is all in the

[843.54 - 848.279] application of Technology

[845.88 - 850.62] so mental illness so this is one thing

[848.279 - 852.06] that is really critical is that uh

[850.62 - 853.92] mental illness is one of the driving

[852.06 - 857.16] factors one of the many driving factors

[853.92 - 858.959] for a belief in a Salvation fantasy the

[857.16 - 861.899] idea that we can invent ourselves out of

[858.959 - 864.54] a problem uh is not necessarily the

[861.899 - 866.279] truth that being said of course you know

[864.54 - 868.86] you can Invent Yourself into problems

[866.279 - 870.36] and you know you might not be able to

[868.86 - 872.5790000000001] invent yourself out of it and so what I

[870.36 - 876.24] mean by that is the example of petroleum

[872.579 - 878.9399999999999] for uh Transportation yes it Advanced uh

[876.24 - 881.04] the human civilization uh tremendously

[878.94 - 883.32] in the 20th century as the Industrial

[881.04 - 886.139] Revolution ramped up but we invented

[883.32 - 888.1990000000001] ourselves into that problem and maybe we

[886.139 - 890.699] can invent ourselves out of that problem

[888.199 - 892.5] by getting to the next level such as

[890.699 - 895.56] solar infusion and that sort of thing

[892.5 - 898.68] but those might introduce new problems

[895.56 - 900.54] and so uh one point here is that maybe

[898.68 - 901.8599999999999] we actually need less technology in our

[900.54 - 903.54] daily lives I'm not saying that we need

[901.86 - 905.16] to like all become luddites and

[903.54 - 907.38] troglodytes and you know burn all the

[905.16 - 909.959] technology down but what I mean is that

[907.38 - 911.639] for instance uh people who use their

[909.959 - 913.38] phone less have demonstrably better

[911.639 - 915.1800000000001] mental health and a better Outlook in

[913.38 - 917.519] the world which is why I use digital

[915.18 - 919.199] Wellness apps on my phone so you know

[917.519 - 921.0] like yesterday I used my phone for a

[919.199 - 922.26] grand total of an hour there are some

[921.0 - 924.6] days that I use my phone for a grand

[922.26 - 926.579] total of 15 minutes and guess what I

[924.6 - 928.5600000000001] definitely feel better on those days so

[926.579 - 930.3] even though the phone your smartphone is

[928.56 - 933.8389999999999] a very very useful piece of technology

[930.3 - 936.54] it comes with its own risks and so then

[933.839 - 938.94] I just want to have like one particular

[936.54 - 941.459] point is that no matter how good your

[938.94 - 943.5600000000001] external situation is even if you live

[941.459 - 944.9399999999999] in the prettiest place on the planet and

[943.56 - 947.579] you're surrounded by friends and family

[944.94 - 950.22] and you have food security and you're in

[947.579 - 953.279] your physically safe the best day in the

[950.22 - 954.899] world does not matter if you have a

[953.279 - 957.899] severe mental illness because that can

[954.899 - 960.36] turn the best day day into ashes

[957.899 - 962.639] um whether it's trauma anxiety

[960.36 - 965.6990000000001] depression loneliness dysmorphia and the

[962.639 - 968.22] list goes on and on and on and so the

[965.699 - 970.92] point is that technology will not solve

[968.22 - 972.9590000000001] mental illness on its own this is this

[970.92 - 976.56] is the this is the primary struggle that

[972.959 - 979.199] many people have and uh this is one of

[976.56 - 981.3] the key things about the false promise

[979.199 - 983.8199999999999] of utopian narratives or salvation

[981.3 - 986.0999999999999] fantasies is that you're offered one

[983.82 - 987.48] solution that is not the actual solution

[986.1 - 989.4590000000001] that you need and we'll get more into

[987.48 - 991.86] that later in the video

[989.459 - 995.9399999999999] all right so a lot of people have asked

[991.86 - 998.759] me to do fdvr videos uh and I've been

[995.94 - 1001.6600000000001] resistant to it because I personally see

[998.759 - 1005.24] fdvr as a kind of Salvation fantasy

[1001.66 - 1008.66] specifically it's an Escape fantasy

[1005.24 - 1012.259] uh so basically the real world sucks so

[1008.66 - 1013.699] just go into uh VR which this was uh

[1012.259 - 1015.259] this was what the movie surrogates was

[1013.699 - 1018.079] about which was about you know basically

[1015.259 - 1019.5790000000001] full dive VR but in a robot uh robotic

[1018.079 - 1021.079] prosthetic and then of course Ready

[1019.579 - 1023.66] Player one is probably the most

[1021.079 - 1026.839] successful book in movie franchise about

[1023.66 - 1029.1789999999999] this thing uh but the idea is that like

[1026.839 - 1032.12] using more technology is not necessarily

[1029.179 - 1034.1000000000001] the answer like I said uh people that

[1032.12 - 1037.2199999999998] use their phones you know Americans are

[1034.1 - 1038.839] near the top globally we use our and I I

[1037.22 - 1041.48] was this way I used my phone about five

[1038.839 - 1044.24] or six hours a day uh when I put the the

[1041.48 - 1046.819] wellness apps on my phone and I had no

[1044.24 - 1047.839] idea that I was using it that much uh

[1046.819 - 1050.54] but

[1047.839 - 1053.84] maybe saturation with VR is going to be

[1050.54 - 1056.36] the same and worse and another thing to

[1053.84 - 1058.3999999999999] keep in mind is that uh VR is being

[1056.36 - 1060.86] created and pushed by corporations with

[1058.4 - 1063.38] a profit motive they do not have your

[1060.86 - 1065.8999999999999] well-being in mind they want they have

[1063.38 - 1067.16] their bottom line in mind now that's not

[1065.9 - 1069.5] to say that corporations are

[1067.16 - 1070.8200000000002] intrinsically evil uh because you know

[1069.5 - 1072.26] they're just trying to make money like

[1070.82 - 1075.2] everyone else

[1072.26 - 1077.539] but it does it does elucidate the

[1075.2 - 1080.419] problem of perverse incentives where if

[1077.539 - 1082.46] you have uh VR or full dive VR or

[1080.419 - 1085.3400000000001] whatever that gives you a more complete

[1082.46 - 1088.16] sensorium experience the possibility for

[1085.34 - 1090.08] addiction is even higher because you

[1088.16 - 1092.3600000000001] know this is a four and a half inch

[1090.08 - 1094.3999999999999] screen and it's relatively low quality

[1092.36 - 1096.3799999999999] and it's certainly not immersive but if

[1094.4 - 1098.66] your phone that is the tiny little

[1096.38 - 1100.7] device can be that addictive how much

[1098.66 - 1102.44] worse could it be if you have you know

[1100.7 - 1106.5800000000002] it basically it's strapped to your face

[1102.44 - 1109.22] and it is more immersive so you know my

[1106.58 - 1111.86] my big concern there is just from a

[1109.22 - 1114.08] biological perspective take business out

[1111.86 - 1118.4599999999998] of it all together and just look at the

[1114.08 - 1120.5] VR device uh just in on on its own and

[1118.46 - 1121.88] the way that it completely hijacks the

[1120.5 - 1124.58] human senses

[1121.88 - 1125.96] uh because something like 70 to 80 of

[1124.58 - 1128.059] the information you get about the world

[1125.96 - 1129.6200000000001] comes in through your eyes a good chunk

[1128.059 - 1132.1399999999999] of the rest comes in through your ears

[1129.62 - 1135.5] and then uh the rest is tactile and

[1132.14 - 1138.5590000000002] orientation such as proprioception uh

[1135.5 - 1141.08] but you know VR fdvr takes care of

[1138.559 - 1142.3999999999999] vision uh and orientation because you're

[1141.08 - 1144.08] moving right so you have some

[1142.4 - 1146.48] proprioception there's actually

[1144.08 - 1148.52] scientific evidence that that

[1146.48 - 1151.16] neurologically when you're in full dive

[1148.52 - 1152.9] VR or not full diver but even just uh VR

[1151.16 - 1154.8200000000002] as it is today your sense of

[1152.9 - 1158.24] proprioception changes you actually feel

[1154.82 - 1161.36] like you are in that environment uh and

[1158.24 - 1163.22] so VR as it is already gets you most of

[1161.36 - 1166.28] the way there to just transcending into

[1163.22 - 1168.6200000000001] a different uh place so from a

[1166.28 - 1171.6789999999999] biological perspective this is something

[1168.62 - 1174.1399999999999] that we need to take very seriously

[1171.679 - 1176.3600000000001] all right so what are the promises that

[1174.14 - 1179.1200000000001] come from technology today this is not

[1176.36 - 1181.1599999999999] just fdvr this could be Robotics and Ai

[1179.12 - 1183.62] and everything else first is

[1181.16 - 1186.799] unconditional love right we've all been

[1183.62 - 1189.32] aware of replica and other uh basically

[1186.799 - 1191.6] AI girlfriends and you know I know that

[1189.32 - 1192.9189999999999] there are people that use uh there are

[1191.6 - 1195.4399999999998] plenty of women that use it on the same

[1192.919 - 1198.679] side but I think on balance more men

[1195.44 - 1201.44] oops sorry more men are interested in AI

[1198.679 - 1203.24] girlfriends than women are interested in

[1201.44 - 1206.299] AI boyfriends and there are of course

[1203.24 - 1208.7] people that are homosexual uh

[1206.299 - 1211.22] using it as well but numerically

[1208.7 - 1212.9] speaking I think that the desire for men

[1211.22 - 1217.1000000000001] to have ai girlfriends is probably

[1212.9 - 1220.52] stronger uh now you know the that that

[1217.1 - 1222.26] promise of unconditional love uh is kind

[1220.52 - 1225.28] of dangerous because that is basically

[1222.26 - 1228.08] hijacking a very basic Primal human need

[1225.28 - 1230.48] if that is going to be provided by a

[1228.08 - 1232.1] for-profit corporation can you see the

[1230.48 - 1235.34] problems there

[1232.1 - 1238.4599999999998] uh it could make you uh basically

[1235.34 - 1239.9599999999998] beholden to that Corporation what if the

[1238.46 - 1242.419] corporation holds your girlfriend

[1239.96 - 1244.3400000000001] hostage and that you know I saw jokes on

[1242.419 - 1246.5590000000002] Reddit and other places like you know

[1244.34 - 1248.8999999999999] what if they add microtransactions

[1246.559 - 1251.78] to your AI girlfriend and that basically

[1248.9 - 1252.98] holds you emotionally hostage uh and

[1251.78 - 1254.78] then of course there's other concerns

[1252.98 - 1256.34] like is this a real relationship is it

[1254.78 - 1258.62] going to make you actually worse at real

[1256.34 - 1261.32] relationships there is some anecdotal

[1258.62 - 1263.36] evidence that uh having an AI partner is

[1261.32 - 1264.98] actually good for your mental health and

[1263.36 - 1266.4189999999999] actually can teach you to be a better

[1264.98 - 1268.039] person to teach you to communicate

[1266.419 - 1270.14] better there's certainly been some

[1268.039 - 1272.24] comments on my own YouTube videos where

[1270.14 - 1273.98] um someone says like oh yeah like chat

[1272.24 - 1276.6200000000001] GPT helped me learn to communicate with

[1273.98 - 1278.66] my wife better great not everyone does

[1276.62 - 1281.4799999999998] that there is a dark side to this where

[1278.66 - 1283.8200000000002] some people are just so uh bitter and

[1281.48 - 1285.38] jaded that they just abuse their AI

[1283.82 - 1287.8999999999999] girlfriends right they use it to take

[1285.38 - 1289.159] out their anger on an AI girlfriend and

[1287.9 - 1291.6200000000001] it's like I don't know that that's

[1289.159 - 1293.3600000000001] healthy but I'm also not here to judge

[1291.62 - 1295.1589999999999] because maybe there is some catharsis

[1293.36 - 1295.9399999999998] there not sure it needs to be studied

[1295.159 - 1299.0590000000002] more

[1295.94 - 1301.64] but my point here is that the salvation

[1299.059 - 1304.6399999999999] fantasy of you know one day you will

[1301.64 - 1306.0200000000002] have a an AI girlfriend or a robot

[1304.64 - 1308.659] girlfriend that loves you

[1306.02 - 1311.48] unconditionally like a dog does

[1308.659 - 1313.1000000000001] um this is I say fantasy like it's a

[1311.48 - 1315.6200000000001] very real possibility

[1313.1 - 1317.48] that it will exist but it comes with

[1315.62 - 1320.059] risks and it comes with strings attached

[1317.48 - 1320.9] that's my that's my primary uh message

[1320.059 - 1323.78] here

[1320.9 - 1326.48] so another one infinite Adventure uh

[1323.78 - 1328.46] basically your AI uh you know friends

[1326.48 - 1330.5] will be ready to take you on the coolest

[1328.46 - 1332.419] adventures and you know you're you're

[1330.5 - 1334.64] gonna have the the sexy Squad that is

[1332.419 - 1336.679] just whatever right they're ready to go

[1334.64 - 1337.94] at all times we already see this with

[1336.679 - 1339.98] video games right like I was playing

[1337.94 - 1341.539] Gears of War 5 and it's like oh cool you

[1339.98 - 1343.24] got some you got some cool friends and

[1341.539 - 1345.44] you're going on a grand epic adventure

[1343.24 - 1349.22] this is going to become even more

[1345.44 - 1351.6200000000001] realistic with uh VR and full dive VR

[1349.22 - 1353.299] now for those of us that are struggling

[1351.62 - 1355.58] with disability and burnout and those

[1353.299 - 1357.799] other things we physically cannot go on

[1355.58 - 1360.28] those kinds of Adventures as an autistic

[1357.799 - 1362.72] person travel is very very hard for me

[1360.28 - 1364.039] airports are basically the worst thing

[1362.72 - 1366.919] in the world because they are

[1364.039 - 1368.179] overwhelming uh they they have too much

[1366.919 - 1370.8200000000002] stimulation there's too much pressure

[1368.179 - 1373.3400000000001] they're very very uncomfortable

[1370.82 - 1375.559] um you know so like even even though I

[1373.34 - 1377.8999999999999] have the money the ability to travel I

[1375.559 - 1380.96] still choose not to because traveling is

[1377.9 - 1383.1200000000001] so miserable for me so while I look

[1380.96 - 1385.7] forward to the ability to go on these

[1383.12 - 1388.3999999999999] Grand adventures with VR and full dive

[1385.7 - 1390.98] VR I am also constantly aware of the

[1388.4 - 1393.0800000000002] fact that it is not real it is a

[1390.98 - 1396.5] synthetic experience not unlike going to

[1393.08 - 1399.1999999999998] the movie theater now one thing to

[1396.5 - 1401.12] consider here is what if VR these VR

[1399.2 - 1403.1000000000001] experiences become preferable to reality

[1401.12 - 1404.6] and then people want to stay in VR

[1403.1 - 1406.8799999999999] longer and longer

[1404.6 - 1409.1] another question is does it have the

[1406.88 - 1411.14] same depth richness and impact as the

[1409.1 - 1413.12] real experiences and then of course

[1411.14 - 1414.5] there's you know loss of Interest loss

[1413.12 - 1417.02] of physical health that sort of stuff

[1414.5 - 1418.34] again I'm not saying that this is not

[1417.02 - 1420.02] going to happen I'm not saying that it

[1418.34 - 1422.84] is a false promise but I'm saying that

[1420.02 - 1425.72] this is a very powerful carrot that is

[1422.84 - 1427.82] going to pull you in and give whoever

[1425.72 - 1430.52] provides that experience to you power

[1427.82 - 1432.3799999999999] over you that is what I that is that is

[1430.52 - 1435.679] the warning I'm issuing here is that

[1432.38 - 1439.1000000000001] those who provide this VR experience

[1435.679 - 1442.0] will have that kind of uh influence and

[1439.1 - 1446.78] control and power over you belonging

[1442.0 - 1448.58] likewise as AI NPCs become more more uh

[1446.78 - 1449.8999999999999] realistic it's going to be more than

[1448.58 - 1452.78] just you know like your AI girlfriend

[1449.9 - 1453.7] it's going to be an entire array of AI

[1452.78 - 1456.2] friends

[1453.7 - 1459.6200000000001] that are just ready to go on whatever

[1456.2 - 1462.38] adventure and they accept you as you are

[1459.62 - 1464.059] provide companionship and again as an

[1462.38 - 1466.3400000000001] autistic person I have very few people

[1464.059 - 1468.2] in the world who actually get me so the

[1466.34 - 1470.24] idea is like wow wouldn't it be cool if

[1468.2 - 1471.679] I had AI friends that I could talk to On

[1470.24 - 1473.24] My Level about the things that I care

[1471.679 - 1475.2800000000002] about and go on the adventures that I

[1473.24 - 1477.38] want to go on and but that is super

[1475.28 - 1479.36] super egocentric

[1477.38 - 1480.6200000000001] um and you know are these superficial

[1479.36 - 1482.299] relationships are they real

[1480.62 - 1484.6999999999998] relationships are they parasocial

[1482.299 - 1486.44] relationships the thing is is once it's

[1484.7 - 1488.48] real enough your brain might not be able

[1486.44 - 1491.24] to tell the difference and so if it is

[1488.48 - 1494.48] real enough to you what does it matter

[1491.24 - 1496.22] uh now you know on the on the on the

[1494.48 - 1498.5] positive side this could fulfill some

[1496.22 - 1501.26] very basic intrinsic uh human needs for

[1498.5 - 1503.419] connection uh another possibility though

[1501.26 - 1505.46] is that because it it could be designed

[1503.419 - 1508.22] to be very egocentric it could make you

[1505.46 - 1509.1200000000001] wait worse at real relationships it

[1508.22 - 1511.039] could make you better at real

[1509.12 - 1513.1999999999998] relationships personally I think it

[1511.039 - 1515.9] would be interesting to have uh some

[1513.2 - 1518.059] realism uh coded into your NPC friends

[1515.9 - 1519.5590000000002] uh where it's like you know they're not

[1518.059 - 1521.24] going to agree with you at all times

[1519.559 - 1522.559] right they're going to push back and say

[1521.24 - 1524.96] you know what like I actually don't like

[1522.559 - 1526.82] it when you do that uh maybe those kinds

[1524.96 - 1528.679] of things could be built in so that even

[1526.82 - 1530.48] if you do spend a lot of time in VR you

[1528.679 - 1534.38] get better at real relationships I don't

[1530.48 - 1536.6] know uh but my point is is that again

[1534.38 - 1539.0590000000002] it's a dual-use sword uh or a dual use

[1536.6 - 1540.86] technology or double-edged sword sorry

[1539.059 - 1542.6] and then the highest thing and this is

[1540.86 - 1545.24] something that that I even talk about a

[1542.6 - 1546.98] lot like the idea of using AI to replace

[1545.24 - 1548.48] functions of government or even to

[1546.98 - 1549.5] eventually replace politicians I don't

[1548.48 - 1551.419] know if that's actually going to happen

[1549.5 - 1553.22] I just threw that out as a possibility

[1551.419 - 1554.779] just so that we can talk about it right

[1553.22 - 1557.6000000000001] my goal here is to move the Overton

[1554.779 - 1560.299] window but the idea that AI could come

[1557.6 - 1563.12] and save us from ourselves this is the

[1560.299 - 1565.1] ultimate utopian salvation fantasy where

[1563.12 - 1567.9189999999999] the idea that we don't trust humans

[1565.1 - 1570.62] humans are garbage let's build a digital

[1567.919 - 1572.3600000000001] God to save us from ourselves this is

[1570.62 - 1574.76] also an abdication of responsibility

[1572.36 - 1577.039] saying I can't fix the mess that I made

[1574.76 - 1578.6] someone else fix it for me which to be

[1577.039 - 1581.6] fair this is true a lot of times in life

[1578.6 - 1583.52] we we often hire help to fix messes you

[1581.6 - 1586.34] hire a lawyer to fix a legal mess you

[1583.52 - 1588.08] hire a mechanic to fix a car mess you

[1586.34 - 1590.4189999999999] hire a doctor to fix your health mess

[1588.08 - 1593.36] right this is what we do we Outsource

[1590.419 - 1595.159] our help to fix things for us but the

[1593.36 - 1597.74] idea is that if you hold this in your

[1595.159 - 1600.0200000000002] mind even at an unconscious level if you

[1597.74 - 1602.659] have this if you have this belief that

[1600.02 - 1604.82] one day a digital savior or a digital

[1602.659 - 1607.8200000000002] God will materialize to save Humanity

[1604.82 - 1610.82] from itself you might be disappointed

[1607.82 - 1612.62] uh because this is basically the promise

[1610.82 - 1616.279] of Salvation and it might be a false

[1612.62 - 1618.799] promise uh now that being said I'm not

[1616.279 - 1621.799] gonna I'm not gonna for a a heartbeat

[1618.799 - 1624.26] say that Ai and Technology will hurt us

[1621.799 - 1626.36] more than it will help us I believe that

[1624.26 - 1628.22] it absolutely could on balance in the

[1626.36 - 1630.26] grand scheme of things help us far more

[1628.22 - 1631.76] than it will hurt us because again

[1630.26 - 1633.44] social media is dependent on the

[1631.76 - 1635.6589999999999] internet and on balance I think the

[1633.44 - 1638.1200000000001] internet is by and large a good thing

[1635.659 - 1641.1200000000001] but you know while the internet can be

[1638.12 - 1642.799] used for sharing news and and scientific

[1641.12 - 1644.9599999999998] research and communicating that sort of

[1642.799 - 1647.539] stuff it can also be used to transmit

[1644.96 - 1651.2] memes and plan you know coup attempts

[1647.539 - 1653.779] and that sort of stuff so uh basically

[1651.2 - 1656.419] be mindful if you do have the Salvation

[1653.779 - 1658.22] fantasy be mindful if you do have this

[1656.419 - 1659.8400000000001] utopian narrative and that you are

[1658.22 - 1662.059] hoping for and expecting a digital

[1659.84 - 1664.3999999999999] savior it may happen it might not

[1662.059 - 1666.62] probably won't at least not anytime soon

[1664.4 - 1667.46] uh but yeah so just something to keep in

[1666.62 - 1669.08] mind

[1667.46 - 1672.679] and I've talked a lot about false

[1669.08 - 1674.84] promises so you know basically you know

[1672.679 - 1676.5800000000002] I mentioned social media a few times but

[1674.84 - 1678.559] the narrative so here's here's the

[1676.58 - 1680.48] narrative that exists particularly in

[1678.559 - 1682.6399999999999] Silicon Valley but it also exists around

[1680.48 - 1684.38] the world is basically just trust us

[1682.64 - 1686.2990000000002] everything will be better once we solve

[1684.38 - 1688.64] just one more problem by inventing

[1686.299 - 1690.9189999999999] another Gadget or Gizmo this comes from

[1688.64 - 1693.0800000000002] Silicon Valley the move move fast and

[1690.919 - 1694.8200000000002] break things mentality not necessarily

[1693.08 - 1697.279] good for society not necessarily good

[1694.82 - 1700.34] for mental health this is also marketing

[1697.279 - 1702.279] 101 bait and switch I make you one

[1700.34 - 1705.02] promise and then give you something else

[1702.279 - 1706.9] the idea is I promise salvation but then

[1705.02 - 1708.74] I just give you a product that has

[1706.9 - 1710.419] microtransactions that's not actually

[1708.74 - 1713.0] salvation this is actually one reason

[1710.419 - 1714.679] that uh yeah if you want to be very

[1713.0 - 1716.539] disillusioned particularly with the West

[1714.679 - 1719.1200000000001] take a course in marketing and

[1716.539 - 1721.52] advertising and learn to recognize all

[1719.12 - 1724.1] of the psychological tricks and tactics

[1721.52 - 1725.96] that they use uh basically anytime you

[1724.1 - 1727.4599999999998] see a pretty person in an ad it's

[1725.96 - 1729.679] basically saying if you buy this good

[1727.46 - 1732.2] service you will be associated with

[1729.679 - 1733.8200000000002] these pretty people or you know if

[1732.2 - 1735.44] you're lonely then you know look at all

[1733.82 - 1737.48] these friends laughing and and having

[1735.44 - 1739.22] you know apparently this is mostly an

[1737.48 - 1741.44] American thing because I think that uh

[1739.22 - 1743.299] advertising that like that is banned in

[1741.44 - 1746.299] Europe I'm not sure

[1743.299 - 1748.52] so what do you do instead instead of

[1746.299 - 1750.799] buying into these salvation fantasies

[1748.52 - 1751.7] and these utopian narratives doubt but

[1750.799 - 1754.279] dream

[1751.7 - 1756.38] uh be skeptical of any of these Grand

[1754.279 - 1758.659] narratives whether they are dystopian or

[1756.38 - 1761.179] utopian some people use dystopian

[1758.659 - 1763.3990000000001] narratives to tap into that nihilism to

[1761.179 - 1765.799] tap into the hopelessness and despair to

[1763.399 - 1767.4189999999999] push their own agenda right because you

[1765.799 - 1769.76] can use the carrot or the stick you can

[1767.419 - 1770.96] use Utopia or dystopia for pretty much

[1769.76 - 1772.94] the same thing which is basically

[1770.96 - 1775.159] corralling and hurting people towards

[1772.94 - 1777.0800000000002] certain conclusions and if it's a

[1775.159 - 1778.8200000000002] corporation or government doing those

[1777.08 - 1780.6789999999999] things they're hurting you towards the

[1778.82 - 1783.4399999999998] conclusion that they want you to believe

[1780.679 - 1785.6000000000001] in which is if it's a corporation just

[1783.44 - 1787.52] buy this just buy this product and then

[1785.6 - 1788.899] your life will be better if it's a if

[1787.52 - 1790.22] it's a government if it's a politician

[1788.899 - 1792.799] they're saying vote for me and your life

[1790.22 - 1795.38] will magically be better uh now without

[1792.799 - 1797.179] that critical mindset you might fall

[1795.38 - 1798.74] into that place of Blind Faith and

[1797.179 - 1801.44] misplaced Trust

[1798.74 - 1804.38] our ability to imagine a better future

[1801.44 - 1806.1200000000001] can be weaponized against you uh

[1804.38 - 1809.5390000000002] societal transformation takes a lot of

[1806.12 - 1811.76] hard work and everything from ending

[1809.539 - 1813.74] slavery universal suffrage and seizing

[1811.76 - 1815.899] the means of production have all been

[1813.74 - 1818.48] those utopian narratives of those

[1815.899 - 1820.1] salvation fantasies that that if you

[1818.48 - 1822.08] just solve this one problem everything

[1820.1 - 1823.58] will be infinitely better but it has

[1822.08 - 1826.58] never been true and it will never be

[1823.58 - 1829.22] true uh that yes technology can solve

[1826.58 - 1830.6589999999999] problems one by one but there is no

[1829.22 - 1832.7] there's not going to be any single

[1830.659 - 1834.919] transformational event that suddenly

[1832.7 - 1837.559] makes the world a perfect utopian place

[1834.919 - 1839.48] yes it will get better but as I

[1837.559 - 1842.1789999999999] mentioned earlier even if the external

[1839.48 - 1844.46] world is perfect in every way everyone

[1842.179 - 1847.039] you know like nobody has to work ever

[1844.46 - 1849.32] again and you get all the food and and

[1847.039 - 1851.179] internet and every all of your needs are

[1849.32 - 1852.3799999999999] taken care of you might still struggle

[1851.179 - 1854.539] with mental health you might still

[1852.38 - 1857.2990000000002] struggle with meaningless uh meaning

[1854.539 - 1859.94] problems and purpose which you know can

[1857.299 - 1862.1] nullify all of those benefits

[1859.94 - 1864.74] without exception technology is a

[1862.1 - 1868.279] double-edged sword it is always dual use

[1864.74 - 1870.34] meaning that the the pros are

[1868.279 - 1874.039] counterbalanced by cons there's always

[1870.34 - 1876.1999999999998] benefits and risks uh to out to all new

[1874.039 - 1878.12] technologies that includes VR that

[1876.2 - 1880.039] includes AI that includes Quantum

[1878.12 - 1882.799] Computing that includes space travel

[1880.039 - 1884.24] right there's all kinds of dystopian

[1882.799 - 1885.98] ways that space travel could be used

[1884.24 - 1888.08] what if all the billionaire Elites just

[1885.98 - 1889.52] leave Earth and say haha you know you're

[1888.08 - 1892.1] screwed now there was an episode about

[1889.52 - 1893.72] uh love death and robots about that and

[1892.1 - 1895.279] I thought it was hilarious because the

[1893.72 - 1896.96] cats ended up on Mars and the cat said

[1895.279 - 1899.36] at the end like what did you expect Elon

[1896.96 - 1901.46] Musk perfect ending I definitely

[1899.36 - 1903.6789999999999] recommend that episode

[1901.46 - 1905.96] um now so basically no matter how

[1903.679 - 1907.64] advanced technology becomes there are

[1905.96 - 1910.88] aspects of the human condition that it

[1907.64 - 1915.0800000000002] will never touch or that it might hurt

[1910.88 - 1917.419] right because like uh there's aspects of

[1915.08 - 1919.9399999999998] The Human Experience whether it's again

[1917.419 - 1921.26] finding meaning finding purpose curing

[1919.94 - 1923.24] Mental Health

[1921.26 - 1926.0] these are things that are intrinsically

[1923.24 - 1928.88] personal now technology can tangentially

[1926.0 - 1931.64] influence them right if you use social

[1928.88 - 1933.2600000000002] media uh and allow yourself to get

[1931.64 - 1935.419] addicted to it it will harm your mental

[1933.26 - 1936.86] health however if you use technology to

[1935.419 - 1939.679] help mental health like finding

[1936.86 - 1941.7199999999998] resources or like the reflective uh

[1939.679 - 1943.3990000000001] journaling chat bot that I built these

[1941.72 - 1946.52] are these are technologies that are not

[1943.399 - 1948.6789999999999] addictive to use but they all they will

[1946.52 - 1950.24] improve your mental health or they can

[1948.679 - 1952.46] I'm not saying they will they can't make

[1950.24 - 1953.8990000000001] that promise but for instance the

[1952.46 - 1956.299] reflective journaling tool that I built

[1953.899 - 1960.3799999999999] helps me

[1956.299 - 1961.8799999999999] um yeah so it's all about remembering uh

[1960.38 - 1963.7990000000002] what you have control over and your

[1961.88 - 1966.38] intrinsic worth but also what is

[1963.799 - 1969.1399999999999] inherently or intrinsically human about

[1966.38 - 1971.0590000000002] life and experience and separating that

[1969.14 - 1972.919] from those utopian narratives and

[1971.059 - 1974.6589999999999] recognizing those utopian narratives for

[1972.919 - 1976.039] what they are which is a Salvation

[1974.659 - 1978.3200000000002] fantasy

[1976.039 - 1980.899] fundamentally it is about hope versus

[1978.32 - 1982.9399999999998] despair whether it's climate change or

[1980.899 - 1986.059] political nihilism or meaning or anxiety

[1982.94 - 1988.3400000000001] and depression this is all the negative

[1986.059 - 1990.32] forces and then the Hope The Shining

[1988.34 - 1992.899] City on the hill is the idea that

[1990.32 - 1995.059] technology or other salvation fantasies

[1992.899 - 1996.799] might help us and one thing that I've

[1995.059 - 1998.6589999999999] observed is that some people are

[1996.799 - 2001.059] incredibly optimistic and some people

[1998.659 - 2003.1000000000001] are incredibly pessimistic it's very

[2001.059 - 2004.4189999999999] very divisive and this is also not the

[2003.1 - 2006.6999999999998] first time in history that that has

[2004.419 - 2008.26] happened the Industrial Revolution was

[2006.7 - 2010.24] the same way a lot of people said yes

[2008.26 - 2012.7] this is going to be great you know we

[2010.24 - 2014.019] can produce food at industrial scales

[2012.7 - 2015.7] but then of course there are other

[2014.019 - 2017.32] people that ended up being harmed the

[2015.7 - 2019.3600000000001] farmers that were put out of work the

[2017.32 - 2021.8799999999999] children that were put in into factories

[2019.36 - 2024.6399999999999] and that were maimed and disabled and

[2021.88 - 2027.7] killed by unsafe working conditions

[2024.64 - 2030.039] right so all technological advances uh

[2027.7 - 2031.539] come with pros and cons as Uncle Ben

[2030.039 - 2033.64] says with great power comes great

[2031.539 - 2036.279] responsibility

[2033.64 - 2038.679] and unfortunately there will be no easy

[2036.279 - 2040.779] answers to any of this meaning purpose

[2038.679 - 2042.7] and healing are up to the individual no

[2040.779 - 2046.84] amount of Technology can fix that for

[2042.7 - 2048.46] you uh and and even worse the whether

[2046.84 - 2051.879] it's hope or despair whether you have

[2048.46 - 2053.919] optimism or pessimism uh those can be

[2051.879 - 2056.139] weaponized against you and used to

[2053.919 - 2058.48] exploit uh either your Vote or your

[2056.139 - 2059.859] wallet or whatever else so be wary of

[2058.48 - 2061.599] the Doomer narratives be wary of the

[2059.859 - 2063.22] utopian narrative some people honestly

[2061.599 - 2065.56] believe that you know the world is

[2063.22 - 2067.5989999999997] completely screwed but the fact they

[2065.56 - 2069.04] keep broadcasting these utopian

[2067.599 - 2071.26] narratives or these Doomer narratives

[2069.04 - 2073.179] basically that shapes the way that

[2071.26 - 2075.2200000000003] people react to everything else and it's

[2073.179 - 2076.96] like ah well we're screwed anyways so

[2075.22 - 2079.9599999999996] what does it matter I don't know that

[2076.96 - 2081.28] that's true likewise the promise that AI

[2079.96 - 2083.919] is going to solve everything for

[2081.28 - 2085.0] everyone forever also not necessarily

[2083.919 - 2088.179] true

[2085.0 - 2090.879] uh the the truth is often uh

[2088.179 - 2093.2200000000003] unfortunately more nuanced more gray and

[2090.879 - 2095.08] usually actually a little more boring uh

[2093.22 - 2097.859] right like the the perfect utopian

[2095.08 - 2100.18] future versus the extinction narrative

[2097.859 - 2101.44] reality will probably be somewhere in

[2100.18 - 2103.54] between those two

[2101.44 - 2106.06] so thanks for watching I hope you got a

[2103.54 - 2107.56] lot out of this uh like subscribe etc

[2106.06 - 2110.4] etc et cetera you know that you know the

[2107.56 - 2110.4] drill cheers