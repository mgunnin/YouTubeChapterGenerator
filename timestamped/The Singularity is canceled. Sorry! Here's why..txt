[0.199 - 6.08] The Singularity has been cancelled I'm

[3.159 - 8.599] sorry everybody time to pack it up and

[6.08 - 10.599] go home now I'm actually kidding just a

[8.599 - 11.88] little bit but there are a few things

[10.599 - 13.4] that I want to unpack about the

[11.88 - 15.639000000000001] singularity and some predictions that

[13.4 - 17.8] people are making and just kind of how

[15.639 - 20.48] people engage with the idea of

[17.8 - 23.080000000000002] technological progress and exponential

[20.48 - 25.199] curves so first we need to unpack what

[23.08 - 26.959999999999997] is the singularity The Singularity is a

[25.199 - 29.199] term that is thrown around a lot and a

[26.96 - 31.080000000000002] lot of people actually are not familiar

[29.199 - 35.120000000000005] with the real definition they haven't

[31.08 - 37.839999999999996] read the book uh but it's basically the

[35.12 - 40.64] hypothetical point in the future where

[37.84 - 42.28] uh technology advances faster and faster

[40.64 - 44.32] and it becomes uncontrollable and

[42.28 - 46.079] irreversible but really the key thing

[44.32 - 48.28] that I want to draw your attention to is

[46.079 - 50.039] unforeseeable changes to human

[48.28 - 51.559] civilization it doesn't mean that

[50.039 - 53.84] there's going to be an event horizon

[51.559 - 55.8] Beyond which all technology and all you

[53.84 - 57.32] know all bets are off and Technology can

[55.8 - 59.959999999999994] do anything that you can possibly

[57.32 - 61.719] imagine now here's some of the points of

[59.96 - 66.0] evidence that lead up to this first

[61.719 - 67.52] exponential growth so right now we have

[66.0 - 70.0] things that seem to be growing

[67.52 - 74.15899999999999] exponentially or logarithmically namely

[70.0 - 76.88] stuff like Mo's law now uh just because

[74.159 - 78.64] things uh are are some things are

[76.88 - 80.52] measurably increasing exponentially

[78.64 - 81.88] other things are not or even if they are

[80.52 - 84.28] growing exponentially it doesn't mean

[81.88 - 86.079] that it's useful so what I mean by this

[84.28 - 87.92] is consider the fact that computers are

[86.079 - 89.439] literally millions of times more

[87.92 - 90.52] powerful than they were during the space

[89.439 - 92.52] race

[90.52 - 95.079] but life is not millions of times more

[92.52 - 97.24] different uh likewise the amount of data

[95.079 - 99.03999999999999] that we're generating is going going up

[97.24 - 101.28] exponentially but it's not really having

[99.04 - 102.96000000000001] that big of an impact on the way that we

[101.28 - 106.119] live or even

[102.96 - 109.0] civilization so despite all of these

[106.119 - 111.36] things I want to like kind of temper

[109.0 - 113.68] your expectations about the future and

[111.36 - 116.479] it is kind of disappointing um I would

[113.68 - 118.119] absolutely love uh for there to be a

[116.479 - 120.759] point in the future where we basically

[118.119 - 122.719] become you know Godlike entities because

[120.759 - 124.96] we have mastered all of time space and

[122.719 - 128.44] energy but that just might not be in the

[124.96 - 130.72] cards for us so why canceled what did it

[128.44 - 133.2] do wrong did it did it make a bad tweet

[130.72 - 137.76] on Twitter or what no that's not what I

[133.2 - 139.67999999999998] mean uh so first is lwh hanging fruit we

[137.76 - 141.39999999999998] have been meticulously picking all of

[139.68 - 144.4] the technological and scientific lwh

[141.4 - 147.64000000000001] hanging fruit that we can uh and we've

[144.4 - 150.59900000000002] been doing this at an increasing clip uh

[147.64 - 153.11999999999998] over the last century now science has

[150.599 - 155.79999999999998] absolutely accelerated in the last even

[153.12 - 158.64000000000001] just the last decade but is this

[155.8 - 160.59900000000002] acceleration permanent I don't think

[158.64 - 162.0] that it is and especially when I talk to

[160.599 - 163.76] my scientist friends and I have quite a

[162.0 - 165.08] few scientist friends they usually just

[163.76 - 166.35999999999999] kind of roll their eyes whenever I

[165.08 - 168.08] mention Singularity they're like

[166.36 - 170.48000000000002] whatever science is hard and it's

[168.08 - 172.12] getting harder fast uh some of my

[170.48 - 173.67999999999998] friends that that they talk about like

[172.12 - 177.36] yeah like there's more papers being

[173.68 - 179.44] published but like each paper is smaller

[177.36 - 183.04000000000002] and smaller in terms of what it actually

[179.44 - 184.92] achiev achieves and so when you consider

[183.04 - 187.2] like maybe there's some diminishing

[184.92 - 191.76] returns maybe there's kind of a vicious

[187.2 - 194.92] cycle there's just not as much to like

[191.76 - 197.84] unpack about the universe anymore so

[194.92 - 200.07999999999998] speaking of that diminishing returns so

[197.84 - 201.4] I just mentioned uh papers uh you know

[200.08 - 203.28] the number of papers is going up

[201.4 - 205.76000000000002] exponentially the number of like

[203.28 - 208.879] fundamental shifts in thinking is

[205.76 - 210.79899999999998] slowing down uh and even if you look at

[208.879 - 212.92] the number of AI papers that are coming

[210.799 - 215.12] out Mo I mean there are entire papers

[212.92 - 217.55999999999997] that are dedicated to like one prompt

[215.12 - 220.36] strategy uh which to me that's worthy of

[217.56 - 221.959] a tweet not a scientific publication um

[220.36 - 223.519] and then of course you know like sure

[221.959 - 225.72] I've I've had arguments with people on

[223.519 - 227.519] LinkedIn and other places about like

[225.72 - 229.28] yeah to anyone who's an experienced

[227.519 - 232.31900000000002] prompt engineer a lot of the things that

[229.28 - 234.48] passes papers um they're not worthy of

[232.319 - 236.76] that but for some people that they only

[234.48 - 239.0] consume information from that particular

[236.76 - 240.72] source and so like scientific

[239.0 - 242.12] Publications particularly in the AI

[240.72 - 244.4] space is basically just becoming a

[242.12 - 246.4] Twitter for scientists and engineers and

[244.4 - 249.28] it's like that's kind of disappointing

[246.4 - 250.28] but it also is just that's the pace of

[249.28 - 252.12] things and that's the way things are

[250.28 - 255.519] being done another thing that I really

[252.12 - 258.6] want to point out is Milestone gaps so

[255.519 - 260.68] the the amount of work that is required

[258.6 - 263.28000000000003] uh in order to get to the next Milestone

[260.68 - 265.0] is increasing exponentially as well so

[263.28 - 268.08] while we have some exponentially

[265.0 - 270.6] increasing uh Technologies we need those

[268.08 - 272.24] exponentially uh increasing Technologies

[270.6 - 275.40000000000003] just in order to get to the next

[272.24 - 277.039] Milestone uh and so you know I've got

[275.4 - 279.79999999999995] some Concepts here like complexity

[277.039 - 282.44] ceiling uh as you pick the lwh hanging

[279.8 - 284.6] fruit the fruit that is remaining to be

[282.44 - 286.639] picked is way higher and so you need

[284.6 - 288.40000000000003] increasingly more sophisticated

[286.639 - 290.28000000000003] Technologies and scientific

[288.4 - 292.15999999999997] understandings and effort in order to

[290.28 - 294.96] get to that so for instance I don't have

[292.16 - 297.199] a chart for it but the cost of drug

[294.96 - 298.84] Discovery has gone up from the tens of

[297.199 - 300.759] thousands to hundreds of thousands to

[298.84 - 303.59999999999997] Millions to to literally billions of

[300.759 - 306.40000000000003] dollars for uh many new drug discoveries

[303.6 - 309.72] today that is an exponential increase in

[306.4 - 311.67999999999995] cost just to discover new drugs and yes

[309.72 - 314.199] Ai and other exponential Technologies

[311.68 - 315.759] are making it a little bit easier but

[314.199 - 317.639] that's just to keep Pace with where we

[315.759 - 319.52000000000004] are this is called Red Queen Theory um

[317.639 - 321.36] in evolution which is basically you have

[319.52 - 324.44] to run as fast as you can just to stay

[321.36 - 327.44] right where you are uh and so because of

[324.44 - 330.24] these diminishing returns I suspect that

[327.44 - 333.68] uh put it this way I don't see any

[330.24 - 335.36] reversing of this trend anytime soon now

[333.68 - 337.72] another thing is that there's probably

[335.36 - 339.639] just mathematical upper bounds to the

[337.72 - 341.84000000000003] laws of physics and artificial

[339.639 - 343.12] intelligence and technology so what I

[341.84 - 344.919] mean by that and I've talked about this

[343.12 - 347.28000000000003] in recent videos but there is a

[344.919 - 349.31899999999996] hypothetical maximum limit to the uh to

[347.28 - 351.88] the like efficiency of computers it's

[349.319 - 353.52000000000004] called the land hour limit but we might

[351.88 - 355.84] not even be able to get remotely close

[353.52 - 358.35999999999996] to the land hour limit and then you know

[355.84 - 360.84] yes there is the hypothetical aspect of

[358.36 - 363.28000000000003] quantum Supremacy Quantum Supremacy

[360.84 - 365.79999999999995] might be able to uh move the needle on

[363.28 - 368.31899999999996] some things but it also might never

[365.8 - 369.84000000000003] really compete with classical Computing

[368.319 - 372.08000000000004] we don't really know just kind of like

[369.84 - 374.56] how analog circuits and digital circuits

[372.08 - 376.12] they don't really like you can compete

[374.56 - 377.88] but it's almost kind of like comparing

[376.12 - 380.44] apples to oranges they just do different

[377.88 - 382.319] things uh there's also some EV some

[380.44 - 385.24] growing evidence that there might be an

[382.319 - 387.639] intelligence ceiling to AI Sam Alman of

[385.24 - 389.84000000000003] all people said the the age of large

[387.639 - 392.44] models might already be over and it

[389.84 - 394.19899999999996] feels like it just got started and so

[392.44 - 396.12] I've talked about this quite extensively

[394.199 - 397.44] in other videos I call it terminal race

[396.12 - 399.52] condition where basically there's a

[397.44 - 402.71999999999997] tradeoff between model size and

[399.52 - 405.71999999999997] intelligence versus speed and efficiency

[402.72 - 407.88000000000005] and in more and more often than not you

[405.72 - 410.24] don't need a gigantic model you need a

[407.88 - 412.96] smaller uh model that is fine-tuned for

[410.24 - 415.12] a particular purpose in order to achieve

[412.96 - 417.68] whatever goals you need and so like

[415.12 - 420.199] there's even if you can hypothetically

[417.68 - 421.919] make an AI more intelligent

[420.199 - 424.12] it just might not be practical it might

[421.919 - 426.84] not be even necessary or

[424.12 - 428.319] useful uh and then finally there's uh

[426.84 - 430.919] useful knowledge which I've got a chart

[428.319 - 433.759] coming up on that but there is a finite

[430.919 - 435.919] amount of knowable stuff at least useful

[433.759 - 438.319] stuff that the amount of data in the

[435.919 - 441.24] universe is hypothetically infinite but

[438.319 - 442.56] the amount of useful and valuable data

[441.24 - 445.199] is not

[442.56 - 447.44] infinite uh now finally what I want to

[445.199 - 449.72] talk about is at least in this in this

[447.44 - 451.8] section of the video is sigmoid curves

[449.72 - 454.16] many many many things in nature follow

[451.8 - 456.28000000000003] sigmoid curves neuron activation

[454.16 - 458.8] population growth learning curves

[456.28 - 460.4] scientific progress and in all

[458.8 - 462.68] likelihood AI development will

[460.4 - 464.79999999999995] eventually be following a sigmoid curve

[462.68 - 466.919] now in the early phases of a sigmoid

[464.8 - 468.879] curve it looks exponential and if you

[466.919 - 470.919] extrapolate that curve based on early

[468.879 - 473.96000000000004] results it looks like it'll go that way

[470.919 - 477.52] forever however eventually a sigmoid

[473.96 - 479.52] curve reverses so this is the heart of

[477.52 - 481.159] this video so I want to talk about this

[479.52 - 483.71999999999997] is a sigmoid curve this is like

[481.159 - 486.4] basically an activation function for you

[483.72 - 489.28000000000003] know a neural network or a neuron or

[486.4 - 491.63899999999995] population growth or whatever so many

[489.28 - 494.479] things in nature follow sigmoid curves

[491.639 - 496.879] the question is where are we on this

[494.479 - 498.87899999999996] sigmoid curve we might be right in the

[496.879 - 501.52000000000004] middle we might also be near the end of

[498.879 - 504.68] the curve uh particularly when you look

[501.52 - 506.639] at um at the basic Sciences uh and I'm

[504.68 - 508.479] not saying like oh we're super close to

[506.639 - 511.0] like discovering everything what I'm

[508.479 - 513.919] saying is that in order to get to that

[511.0 - 515.599] maximum part where we have that plateau

[513.919 - 518.0799999999999] of where we've mastered all of basic

[515.599 - 520.0390000000001] Sciences it's going to get exponentially

[518.08 - 522.039] more difficult and expensive to get

[520.039 - 525.24] there uh and we're already seeing this

[522.039 - 526.76] in many Sciences uh but you know it

[525.24 - 528.519] might feel like we're still at the

[526.76 - 531.04] beginning of the curve but the the

[528.519 - 532.6] problem with sigmoid curves is that if

[531.04 - 535.7199999999999] you're in the middle third you kind of

[532.6 - 538.24] don't know how far along you are because

[535.72 - 541.5600000000001] the the slope of the curve is not very

[538.24 - 544.76] different um from one point to the next

[541.56 - 546.7199999999999] uh and so we're not really sure like how

[544.76 - 548.48] far along we are and it might be

[546.72 - 551.24] impossible to predict how far like

[548.48 - 553.399] because if we are in the bottom third

[551.24 - 555.0790000000001] still like if we're if we're down here

[553.399 - 557.04] then it's like okay well Dave like

[555.079 - 558.56] you're completely wrong and even just

[557.04 - 560.12] when we get to the midpoint that'll feel

[558.56 - 563.3199999999999] like the singularity let alone when we

[560.12 - 565.9590000000001] get near the end but personally when you

[563.32 - 568.72] look at the rate of change uh in terms

[565.959 - 570.88] of the way that Society has changed

[568.72 - 572.6800000000001] societ has already slowed down

[570.88 - 574.64] drastically like I mentioned at the

[572.68 - 577.8] beginning of the video we have space

[574.64 - 580.079] flight we have you know infinitely more

[577.8 - 583.279] powerful computers than we used to we

[580.079 - 584.8389999999999] have Alpha fold 2 we We've Got Deep Mind

[583.279 - 587.64] we've got all these things and we've got

[584.839 - 590.32] just this exponentially uh increasing

[587.64 - 592.4399999999999] amount of technology and science and

[590.32 - 594.6800000000001] understanding but Society hasn't really

[592.44 - 597.0790000000001] changed in 10 years or 20 years or 30

[594.68 - 598.56] years you watch videos of like you know

[597.079 - 601.8389999999999] what happened in the '90s and it's like

[598.56 - 604.04] we more or live the same way uh and so

[601.839 - 607.0] I'm I'm not convinced that that the

[604.04 - 608.7199999999999] singularity even even uh the the formal

[607.0 - 610.36] definition of the singularity where

[608.72 - 612.32] human civilization becomes

[610.36 - 613.32] unrecognizable I'm not even convinced

[612.32 - 615.6] that's going to

[613.32 - 617.9200000000001] happen now with that being said there

[615.6 - 620.399] are these uh what I call these epocal

[617.92 - 622.56] thresholds where basically like okay yes

[620.399 - 624.8] for for many hundreds of thousands of

[622.56 - 626.88] years humans basically lived as hun

[624.8 - 629.88] gathers and then you know we started to

[626.88 - 632.32] take off and we got you know the uh

[629.88 - 633.959] the Iron Age and the Bronze Age which

[632.32 - 636.519] you know Global phenomenon and then we

[633.959 - 638.1999999999999] got to you know the age of Steel and

[636.519 - 641.24] steam and then we got to the Industrial

[638.2 - 644.279] Revolution and so like yes Humanity has

[641.24 - 645.839] gone through many uh epocal changes has

[644.279 - 648.279] crossed many of these

[645.839 - 651.32] thresholds we might be in the midst of

[648.279 - 653.0] the last threshold we might be there

[651.32 - 655.32] might be one or two more thresholds we

[653.0 - 657.04] don't know uh but I'm not really

[655.32 - 659.519] convinced that it's going to be like

[657.04 - 661.56] that drastically different cuz even when

[659.519 - 663.48] in like 1900 someone said you know

[661.56 - 665.7199999999999] humans have already invented 90% of

[663.48 - 667.6800000000001] everything that is inventable we still

[665.72 - 670.0] live relatively similar to how we did at

[667.68 - 672.079] the turn of the century we go to jobs

[670.0 - 674.279] you know we have factories we have

[672.079 - 676.92] machines uh you know we have a few

[674.279 - 679.2] niftier like machines like we've got

[676.92 - 681.8] iPhones now but that does that hasn't

[679.2 - 685.0790000000001] really fundamentally changed how we live

[681.8 - 688.24] okay so this is a graphic that I've had

[685.079 - 690.7199999999999] in my head for a while and basically you

[688.24 - 692.8] know like all day in the universe is

[690.72 - 695.0] superset so like if you if if you think

[692.8 - 697.76] about the the universe as an information

[695.0 - 700.0] model there is technically an infinite

[697.76 - 702.4399999999999] amount of possible information and data

[700.0 - 705.32] in the universe however a much smaller

[702.44 - 707.12] subset of that is all useful knowledge

[705.32 - 708.5600000000001] so there's there's raw data there's

[707.12 - 710.12] information and then there's knowledge

[708.56 - 712.4399999999999] and then there's wisdom if you want to

[710.12 - 714.72] you know think about it like that the

[712.44 - 717.0] amount of information that is actually

[714.72 - 719.0790000000001] classifiable as useful knowledge is far

[717.0 - 721.519] smaller than the amount of actual data

[719.079 - 725.04] in the universe and then of course all

[721.519 - 727.279] human knowledge is a is a uh subset of

[725.04 - 728.92] useful knowledge but eventually we will

[727.279 - 731.04] get to the point where we have captured

[728.92 - 732.24] all useful knowledge yes like I said

[731.04 - 734.24] there's an infinite amount of

[732.24 - 736.32] information and data in the universe but

[734.24 - 738.48] a lot of that is just noise and so the

[736.32 - 740.12] signal to noise ratio is another thing

[738.48 - 742.279] that I think is following a sigmoid

[740.12 - 745.079] curve and it's kind of already tapering

[742.279 - 747.279] off you know it's like it's not like you

[745.079 - 750.4799999999999] sure we understand subatomic particles

[747.279 - 751.76] and gravitons and and higs bosen and you

[750.48 - 754.9200000000001] know there's all kinds of tiny

[751.76 - 756.199] fundamental things um and maybe I'm

[754.92 - 758.399] wrong you know we still haven't fully

[756.199 - 760.639] untangled dark matter and dark energy

[758.399 - 762.199] and so maybe there are entire domains of

[760.639 - 764.44] science that are just like out there in

[762.199 - 766.279] The Ether that are completely unknown

[764.44 - 768.44] but at the same time I kind of get the

[766.279 - 770.399] sense that even if it is out there it's

[768.44 - 772.0790000000001] it's part of that it's exponent the the

[770.399 - 774.639] Milestones are exponentially getting

[772.079 - 776.6389999999999] further and further apart so I don't

[774.639 - 778.48] really see us conquering all that

[776.639 - 780.279] necessarily like in the foreseeable

[778.48 - 781.9590000000001] future and even if we do is it going to

[780.279 - 784.56] change Human

[781.959 - 786.5189999999999] Society okay so I've rained on

[784.56 - 788.92] everyone's parade what are the

[786.519 - 791.079] implications so the first and biggest

[788.92 - 793.519] question is where is the plateau if

[791.079 - 795.12] indeed scientific and technological

[793.519 - 796.48] progress is following a sigmoid curve

[795.12 - 799.12] which I believe there is plenty of

[796.48 - 801.0] evidence that it is where is the plateau

[799.12 - 803.399] where is it going to taper off and where

[801.0 - 805.199] are we going to end up so again like I

[803.399 - 807.32] said finite amount of knowledge uh

[805.199 - 809.519] useful knowledge in the universe there's

[807.32 - 811.9590000000001] also this kind of Di finishing returns

[809.519 - 814.079] or vicious cycle where yes every time we

[811.959 - 817.04] make progress it's great but also the

[814.079 - 818.959] complexity goes up uh in lock step with

[817.04 - 820.519] that and so it's like okay that's what I

[818.959 - 821.959] mean by like every threshold gets

[820.519 - 824.519] further and further

[821.959 - 826.5999999999999] apart now this is one thing that I

[824.519 - 828.5600000000001] really take issue with is the idea that

[826.6 - 831.32] there is some kind of predictability

[828.56 - 833.6389999999999] horizon or Event Horizon Beyond which

[831.32 - 837.36] all all bets are off and and everything

[833.639 - 839.16] changes and suddenly you know life

[837.36 - 841.0] becomes fundament mentally

[839.16 - 843.0] unrecognizable and human civilization

[841.0 - 844.88] changes forever and we all live as

[843.0 - 846.079] goldfish and you know spice tanks or

[844.88 - 848.48] whatever I don't

[846.079 - 850.199] know but I don't really see any evidence

[848.48 - 851.48] of that and like I said I'm like one of

[850.199 - 853.12] the kinds of people that like I would

[851.48 - 855.36] love to have warp drive I would love to

[853.12 - 858.0] have like all kinds of stuff that just

[855.36 - 860.0] might not be possible I remember I had a

[858.0 - 862.48] conversation with a friend of mine uh

[860.0 - 864.279] many years ago good good scientist and I

[862.48 - 865.88] was talking me like when are we going to

[864.279 - 868.36] get faster than light travel and he was

[865.88 - 869.8] like it might just not be possible uh

[868.36 - 871.279] and I address that closer to the end of

[869.8 - 873.0] the video but it like that really stuck

[871.279 - 875.36] with me he's like you know we need to

[873.0 - 877.519] accept the possibility that there are

[875.36 - 880.04] just things that yes we can imagine them

[877.519 - 882.68] as happening but they're just not going

[880.04 - 885.04] to happen jump Gates might not be

[882.68 - 886.5999999999999] possible uh you know warp drive might

[885.04 - 888.7199999999999] not be possible hyperdrive whatever you

[886.6 - 890.5600000000001] want to call it these things like we can

[888.72 - 893.1600000000001] imagine them sure but they might forever

[890.56 - 895.2399999999999] be within the realm of

[893.16 - 897.92] fantasy all right so I already mentioned

[895.24 - 899.5600000000001] aacle thresholds typically we record

[897.92 - 901.759] aacle threshold holds his industrial

[899.56 - 904.4799999999999] revolutions the Renaissance was another

[901.759 - 906.44] big one uh you know the Stone Age

[904.48 - 908.639] transition to the uh to the Bronze Age

[906.44 - 911.519] and the Iron Age those could be viewed

[908.639 - 913.759] as uh epocal thresholds the invention of

[911.519 - 916.199] sale in order to circumnavigate the

[913.759 - 918.1990000000001] world um these kinds of things the

[916.199 - 919.5999999999999] biggest question to me is are we in the

[918.199 - 922.12] last one is the fourth Industrial

[919.6 - 923.16] Revolution the last apocal threshold

[922.12 - 925.0] obviously I'm not going to be so

[923.16 - 926.16] shortsighted as to say we have invented

[925.0 - 927.959] everything that is possible to be

[926.16 - 931.079] invented I remember when I read that

[927.959 - 932.8389999999999] quotation like probably I was like 10 or

[931.079 - 934.3599999999999] 11 when I read that I'm like wow that

[932.839 - 935.6800000000001] dude was an idiot so I'm not going to

[934.36 - 937.0790000000001] fall into that trap and say we've

[935.68 - 939.4799999999999] invented everything that it is possible

[937.079 - 942.0] to invent no what I am saying though is

[939.48 - 944.3190000000001] that even with accelerating technology

[942.0 - 946.48] and science the way that we live is not

[944.319 - 948.5999999999999] changing at an accelerated rate if

[946.48 - 952.1990000000001] anything the way that we live is

[948.6 - 954.72] changing at a slower rate um so yes can

[952.199 - 956.68] things get better absolutely uh can

[954.72 - 958.759] things still change yes absolutely can

[956.68 - 960.7199999999999] we become a multiplanetary species I

[958.759 - 962.319] don't see why not but I'm not saying

[960.72 - 963.759] that it's going to be easy and I think

[962.319 - 965.8389999999999] that this is one of the fantasies that

[963.759 - 967.5600000000001] people have is that with more and more

[965.839 - 969.6800000000001] technological breakthroughs things are

[967.56 - 970.88] just going to get exponentially easier I

[969.68 - 974.0] do think that some things will get

[970.88 - 976.079] easier obviously we would rather live uh

[974.0 - 978.12] today with our technology that we have

[976.079 - 981.04] today than we would like to live 200

[978.12 - 982.92] years ago because why there's a lot of

[981.04 - 984.5999999999999] things that are way easier today but

[982.92 - 988.199] that doesn't mean that life is overall

[984.6 - 991.8000000000001] very easy uh so and again the Event

[988.199 - 993.079] Horizon is basically like I whenever

[991.8 - 995.079] people talk about Singularity and

[993.079 - 997.4799999999999] whenever I think about Singularity it's

[995.079 - 999.04] like I don't really see this happening

[997.48 - 1000.639] if you want to talk about a point of no

[999.04 - 1003.48] return I think we crossed that a long

[1000.639 - 1005.36] time ago uh and we crossed that and it

[1003.48 - 1006.839] was inevitable not by virtue of the

[1005.36 - 1008.9590000000001] technology or the science but just

[1006.839 - 1011.1600000000001] because the planet is so huge and

[1008.959 - 1013.319] there's billions of us and you can no

[1011.16 - 1015.639] more stop research happening in China or

[1013.319 - 1016.959] Russia or Africa or America or Europe

[1015.639 - 1019.44] then you can like stop the Earth from

[1016.959 - 1021.6389999999999] spinning why because it's impossible to

[1019.44 - 1023.44] coordinate 8 billion humans like granted

[1021.639 - 1026.0] we didn't have 8 billion humans in 1950

[1023.44 - 1028.839] we had like 3 billion but the point is

[1026.0 - 1032.12] is that there is an inexorable process

[1028.839 - 1034.0] of of of human progress and learning and

[1032.12 - 1035.319] everything that you just can't stop it

[1034.0 - 1036.76] so if you want to talk about a point of

[1035.319 - 1039.4389999999999] no return we crossed that a long time

[1036.76 - 1043.16] ago it's slow it's been a slow

[1039.439 - 1044.72] buildup but the the aspect of this you

[1043.16 - 1046.48] know technological Event Horizon and

[1044.72 - 1048.96] Singularity that I really want to push

[1046.48 - 1051.2] back on is the magical thinking that

[1048.96 - 1053.8400000000001] seems to emerge where some people say

[1051.2 - 1057.28] they they just there's this inflation

[1053.84 - 1060.0] where the it's like okay well someone

[1057.28 - 1062.6399999999999] predicted that you know Human Society

[1060.0 - 1064.44] civilization might become unrecognizable

[1062.64 - 1066.96] first I don't see any evidence of that

[1064.44 - 1069.039] and second that that that is often

[1066.96 - 1070.8400000000001] inflated or conflated with we'll shatter

[1069.039 - 1073.96] all the laws of physics and anything you

[1070.84 - 1075.48] can imagine will be possible again like

[1073.96 - 1076.799] I'm not seeing any evidence of that and

[1075.48 - 1079.159] in fact I'm seeing evidence to the

[1076.799 - 1080.84] contrary that even though we have uh

[1079.159 - 1083.0] exponentially better understanding of

[1080.84 - 1087.039] the fundamental laws of physics things

[1083.0 - 1088.799] are changing slower and slower uh and

[1087.039 - 1090.96] also the reason that I want to push back

[1088.799 - 1094.1589999999999] on this it is it can be a very harmful

[1090.96 - 1097.039] narrative like it's it it can be as bad

[1094.159 - 1098.919] as like you know uh narratives of

[1097.039 - 1100.799] Destruction or utopian narratives or

[1098.919 - 1102.5590000000002] anything where it's like if you imagine

[1100.799 - 1104.8799999999999] that the future will be unimaginably

[1102.559 - 1106.6789999999999] better and happier and safer and and

[1104.88 - 1108.5200000000002] everything and then you ignore the

[1106.679 - 1111.1200000000001] problems today and you stop putting

[1108.52 - 1112.96] effort today uh well I mean that could

[1111.12 - 1115.1589999999999] that could have negative consequences as

[1112.96 - 1118.039] well it could result in like learned

[1115.159 - 1120.6000000000001] helplessness or a sense of futility or

[1118.039 - 1122.36] fertility or just delaying your life

[1120.6 - 1125.24] like there's a lot to enjoy

[1122.36 - 1126.799] today okay so those are some of the

[1125.24 - 1128.6] implications here are some of my

[1126.799 - 1131.44] specific predictions about what will

[1128.6 - 1133.36] happen um within the foreseeable future

[1131.44 - 1137.039] in terms of how it will change how we

[1133.36 - 1138.9189999999999] live so first indefinite lifespan this

[1137.039 - 1140.559] is one that I think that there's plenty

[1138.919 - 1143.24] of evidence that it that we are working

[1140.559 - 1145.2] up to this very quickly I don't know why

[1143.24 - 1147.0] but but talking about indefinite

[1145.2 - 1149.039] lifespan seems to trigger some people on

[1147.0 - 1151.24] the internet not not most but there's a

[1149.039 - 1152.84] few I always get a couple comments where

[1151.24 - 1154.64] people are like oh well people have been

[1152.84 - 1156.6] predicting you know the the Fountain of

[1154.64 - 1157.919] of Youth for centuries and you're not

[1156.6 - 1159.9599999999998] going to find it and nobody's going to

[1157.919 - 1161.88] find it and it's like I don't know those

[1159.96 - 1163.24] people seem to have a Death Wish they're

[1161.88 - 1165.7600000000002] like just stop telling me that I'm going

[1163.24 - 1167.919] to live forever like that makes me angry

[1165.76 - 1170.559] I don't I don't understand that reaction

[1167.919 - 1172.2] um but so there's there's plenty of

[1170.559 - 1173.72] evidence that we are getting close to

[1172.2 - 1174.799] this and I remember there was a comment

[1173.72 - 1176.6000000000001] that I got a few weeks ago that

[1174.799 - 1178.32] someone's like yeah but what about these

[1176.6 - 1180.039] plaques and proteins and enzymes that

[1178.32 - 1183.24] accumulate I'm like the fact that you

[1180.039 - 1185.12] know like what causes aging means that

[1183.24 - 1186.799] like that's half the battle right there

[1185.12 - 1189.12] was this famous quotation who was it was

[1186.799 - 1191.679] it Ray CTSV I think it was Ray CTSV

[1189.12 - 1193.7199999999998] during the Human Genome Project um

[1191.679 - 1195.919] someone consulted with him and it's like

[1193.72 - 1197.159] oh well we've only decoded uh 1% of the

[1195.919 - 1199.5200000000002] genome and he's like okay well we're

[1197.159 - 1201.0800000000002] halfway done um that is the nature of

[1199.52 - 1202.76] exponential progress and that is one

[1201.08 - 1205.0] place that I agree with him because as

[1202.76 - 1207.52] an automation engineer if you can

[1205.0 - 1209.84] automate 1% of the job you can automate

[1207.52 - 1212.08] 100% of the job why because it's just a

[1209.84 - 1213.76] matter of like one more step to get

[1212.08 - 1216.559] something that will finish the process

[1213.76 - 1218.32] for you and I've had chats with other

[1216.559 - 1220.2] people in Automation and they agree it's

[1218.32 - 1221.84] like with Automation and that kind of

[1220.2 - 1223.3600000000001] thing it's like it feels like you

[1221.84 - 1226.24] achieve nothing till the very end then

[1223.36 - 1229.3999999999999] you hit go and then it's done um but

[1226.24 - 1232.72] yeah so the combination of of precedents

[1229.4 - 1235.039] that we see in nature the rapid pace of

[1232.72 - 1236.64] understanding genetics nanotechnology

[1235.039 - 1238.559] like man some of the stuff that I've

[1236.64 - 1240.0] seen just in the last few weeks about

[1238.559 - 1242.559] nanotech being able to like have

[1240.0 - 1244.2] programmatic uh like programmable Nano

[1242.559 - 1247.84] particles that will deliver drugs to

[1244.2 - 1251.0] specific tissues uh honestly I don't see

[1247.84 - 1253.039] any any reason any physical reason that

[1251.0 - 1255.84] we could not within a reasonable time

[1253.039 - 1259.1589999999999] frame relatively soon overcome all of

[1255.84 - 1260.9189999999999] the uh causes of Aging and death at

[1259.159 - 1262.3600000000001] least all the known ones obviously it's

[1260.919 - 1264.8400000000001] entirely possible that the longer you

[1262.36 - 1267.6] live the more likelihood there will be

[1264.84 - 1270.76] you know for accidents or unpredictable

[1267.6 - 1273.08] diseases for instance you know uh 100

[1270.76 - 1275.559] years ago there was probably a lot less

[1273.08 - 1276.96] um uh understanding of things like

[1275.559 - 1278.44] Alzheimer's and stuff just because

[1276.96 - 1279.2] people didn't live long enough to have

[1278.44 - 1281.679] those

[1279.2 - 1284.52] diseases but I do suspect that

[1281.679 - 1287.159] indefinite lifespan is coming relatively

[1284.52 - 1289.12] soon and this this might very well be

[1287.159 - 1290.96] the biggest single impact to the way

[1289.12 - 1293.36] that we live it's going to change the

[1290.96 - 1296.32] way that we relate to ourselves to each

[1293.36 - 1297.7199999999998] other to politics to economics to power

[1296.32 - 1299.84] it's going to change the way that we do

[1297.72 - 1301.72] Family Planning it's going to change the

[1299.84 - 1303.559] the way that we engage with life and fun

[1301.72 - 1305.1200000000001] and Leisure and all that kind of stuff

[1303.559 - 1308.48] so this I think is going to be the

[1305.12 - 1311.32] biggest like most fundamental shift in

[1308.48 - 1313.279] society cybernetic integration I did do

[1311.32 - 1316.08] a recent video about neuralink I think

[1313.279 - 1317.76] that neuralink as it is is very uh

[1316.08 - 1319.36] immature and I don't mean like childish

[1317.76 - 1322.679] I just mean it's it's an immature

[1319.36 - 1325.799] technology that being said there is a

[1322.679 - 1327.679] lot of other research being done with uh

[1325.799 - 1329.4] impl cybernetic implants of all

[1327.679 - 1332.72] different kinds not just brain computer

[1329.4 - 1335.2] interfaces there are uh Rejuvenation uh

[1332.72 - 1337.2] things such as like bio engineered like

[1335.2 - 1339.159] semi- living implants that can cure type

[1337.2 - 1341.64] 1 diabetes I just saw that the other day

[1339.159 - 1343.96] that's really cool there's also the

[1341.64 - 1345.3200000000002] possibility of like uh there's another

[1343.96 - 1346.8400000000001] implant that I was watching a video

[1345.32 - 1348.48] about that it like it can regrow your

[1346.84 - 1352.32] liver so it's like

[1348.48 - 1354.48] Okay cool so we have lots and lots of of

[1352.32 - 1357.559] implants and cybernetic integration

[1354.48 - 1360.279] coming down the pipeline so most of

[1357.559 - 1362.1589999999999] these are focused on um on disease and

[1360.279 - 1364.2] injury so like you know there's some

[1362.159 - 1365.96] electrical implants that looks like they

[1364.2 - 1367.64] can cause your spine to regrow if you've

[1365.96 - 1370.799] broken your broken your spine and you've

[1367.64 - 1372.72] been paralyzed that's really cool but

[1370.799 - 1375.48] there's a really big difference between

[1372.72 - 1376.559] repairing damage and and enhancements

[1375.48 - 1379.039] with new

[1376.559 - 1381.52] capabilities uh and there's also

[1379.039 - 1383.64] possibly or likely limitations to the

[1381.52 - 1385.6] level of integration now in fictional

[1383.64 - 1387.48] places like cyberpunk there's this you

[1385.6 - 1389.0] know disease called cyber psychosis

[1387.48 - 1392.6] where basically if you have too many

[1389.0 - 1394.64] implants you start to go crazy um in

[1392.6 - 1396.6789999999999] Ghost in the Shell there is a cyber

[1394.64 - 1398.6000000000001] cyberbrain sclerosis which is basically

[1396.679 - 1400.44] like your immune system uh and

[1398.6 - 1402.32] inflammation responses to implants

[1400.44 - 1405.0800000000002] basically cause your brain to harden and

[1402.32 - 1406.84] you lose your ability to think uh really

[1405.08 - 1409.3999999999999] horrible possible diseases that could

[1406.84 - 1410.6399999999999] emerge like we could create new diseases

[1409.4 - 1412.5590000000002] with cybernetics so we need to be

[1410.64 - 1414.3600000000001] careful with that now that being said

[1412.559 - 1415.9189999999999] like maybe in the long run there's no

[1414.36 - 1418.559] reason we can't overcome these things

[1415.919 - 1422.159] especially if you have forever to figure

[1418.559 - 1424.799] it all out okay great robotic Workforce

[1422.159 - 1426.8400000000001] I am a huge proponent of what I call

[1424.799 - 1429.32] post- labor economics and I just think

[1426.84 - 1431.799] that it makes sense to uh get humans out

[1429.32 - 1433.2] of the workforce as much as possible uh

[1431.799 - 1435.44] and I think it's inevitable I think it

[1433.2 - 1438.8400000000001] makes economic sense to replace human

[1435.44 - 1441.039] labor um I think that there is is no

[1438.84 - 1442.3999999999999] reason that we need jobs so this is

[1441.039 - 1443.76] another thing that seems to trigger some

[1442.4 - 1447.1200000000001] people I've talked about the existence

[1443.76 - 1449.08] of leisure classes so uh Greek

[1447.12 - 1451.12] aristocracy back in the day Roman

[1449.08 - 1453.96] aristocracy back in the day British

[1451.12 - 1456.039] aristocracy up through today like there

[1453.96 - 1457.52] are literally entire civilizations that

[1456.039 - 1461.0] had classes of people who were not

[1457.52 - 1462.96] allowed to work so like and they were

[1461.0 - 1465.919] fine like you don't need work to have a

[1462.96 - 1468.679] meaningful fulfilling life um Spartan

[1465.919 - 1470.2] Spartan uh men citizens like they were

[1468.679 - 1472.88] literally not allowed to have a job you

[1470.2 - 1474.919] were not allowed to have a profession um

[1472.88 - 1477.0390000000002] if you were a member of a certain crust

[1474.919 - 1479.0] of society and in fact you can even see

[1477.039 - 1480.799] this go watch Downtown Abby when what's

[1479.0 - 1482.2] his name joins and he's like a lawyer

[1480.799 - 1483.8799999999999] it's like oh well that's kind of low

[1482.2 - 1486.64] brow like why are you still working for

[1483.88 - 1488.3200000000002] money you're one of us now like this

[1486.64 - 1489.919] still exists today so I don't know why

[1488.32 - 1491.9189999999999] talking about a Leisure Class like

[1489.919 - 1493.6000000000001] triggers some people but it does but I

[1491.919 - 1495.039] want to point out the fact that like

[1493.6 - 1496.9599999999998] there have been millions and millions of

[1495.039 - 1499.039] people throughout all of history that

[1496.96 - 1501.1200000000001] did not have a profession and in some

[1499.039 - 1502.52] cases were legally prohibited from

[1501.12 - 1505.32] having a profession and they were

[1502.52 - 1508.399] perfectly happy they had really cool

[1505.32 - 1511.039] parties um but yeah and so the primary

[1508.399 - 1514.6] the the primary kpi that I look for as

[1511.039 - 1516.24] evidence for replacing human labor is

[1514.6 - 1518.799] better faster cheaper and safer those

[1516.24 - 1520.48] are the like four criteria that pay

[1518.799 - 1522.799] attention to that in terms of artificial

[1520.48 - 1524.96] intelligence and Ai and I still get like

[1522.799 - 1526.679] comments saying someone like oh well I'd

[1524.96 - 1528.88] love to see a robot take my job doing

[1526.679 - 1530.8400000000001] tiling it's like you should check on

[1528.88 - 1533.44] some of the latest uh things that robots

[1530.84 - 1535.08] are capable of doing um robots are

[1533.44 - 1537.48] taking really cool form factors they're

[1535.08 - 1539.36] getting much more dextrous very quickly

[1537.48 - 1541.2] and then you look at the the the work

[1539.36 - 1544.6399999999999] that I'm doing on the ace framework that

[1541.2 - 1545.96] Google's doing on RTX and like these

[1544.64 - 1547.8400000000001] these robots are going to be able to do

[1545.96 - 1550.0] pretty much anything very soon I'm

[1547.84 - 1551.9189999999999] predicting probably this time next year

[1550.0 - 1553.64] we're going to start to see uh

[1551.919 - 1556.919] commercial robots that are able to do

[1553.64 - 1558.7990000000002] pretty much any blue collar work uh like

[1556.919 - 1561.7990000000002] mark my words I'll probably do like a

[1558.799 - 1563.6399999999999] prediction Poll for that uh okay so then

[1561.799 - 1566.32] probably the most extreme thing is going

[1563.64 - 1568.5200000000002] to be transgenic technology we can

[1566.32 - 1570.799] already do a lot of this uh it's still a

[1568.52 - 1573.039] very naive technology or an immature

[1570.799 - 1576.36] technology but the fact that we can even

[1573.039 - 1578.36] replace organel in cells and then inject

[1576.36 - 1580.08] that into the into the germ line and

[1578.36 - 1581.8799999999999] what I mean by that is like there are

[1580.08 - 1583.84] certain diseases that are based on uh

[1581.88 - 1585.159] defective mitochondria and so what you

[1583.84 - 1587.039] can do is you can take a healthy

[1585.159 - 1588.8400000000001] mitochondria from another cell and

[1587.039 - 1590.44] replace your mitochondria with it and

[1588.84 - 1594.76] then because mitochondria have their own

[1590.44 - 1596.64] DNA it repl it it it um it reproduces

[1594.76 - 1598.32] when your cells go through mitosis and

[1596.64 - 1601.919] so it's like hey you've now created a

[1598.32 - 1604.9189999999999] cell that is a Franken cell uh based on

[1601.919 - 1607.0] input from multiple organisms uh so

[1604.919 - 1610.72] between genome editing and epig genomic

[1607.0 - 1613.72] editing and organel replacement uh like

[1610.72 - 1617.0] we literally have actual control over

[1613.72 - 1619.48] the the fundamental levers of biology uh

[1617.0 - 1622.36] now again like most Technologies and

[1619.48 - 1624.24] Sciences we are going to find you know

[1622.36 - 1626.8799999999999] maybe some diminishing returns some

[1624.24 - 1629.88] increasing complexity but there is no

[1626.88 - 1631.88] physical barrier to like modifying our

[1629.88 - 1635.279] genes now are we going to all be cat

[1631.88 - 1637.3990000000001] people one day some people might you

[1635.279 - 1640.96] know if that if that's what they want

[1637.399 - 1642.9599999999998] great it's not what I want um I probably

[1640.96 - 1644.48] will remain like kind of in this form

[1642.96 - 1646.3990000000001] factor more or less for the foreseeable

[1644.48 - 1648.0] future now granted you know you live for

[1646.399 - 1649.52] 10,000 years you might get bored and you

[1648.0 - 1653.159] want to be a cat person for a while I

[1649.52 - 1655.44] don't know um but there's also

[1653.159 - 1657.0800000000002] like it's difficult to talk about this

[1655.44 - 1658.76] stuff without saying like wow but that

[1657.08 - 1661.399] is intrinsically wrong because we should

[1658.76 - 1663.8799999999999] just be humans forever um but like I

[1661.399 - 1665.9599999999998] don't know that's it's weird also

[1663.88 - 1667.3200000000002] because this is this is super polarizing

[1665.96 - 1669.3990000000001] where some people are like well yeah

[1667.32 - 1670.8799999999999] obviously like if we if we have control

[1669.399 - 1672.9189999999999] over that and we want to change

[1670.88 - 1674.0] ourselves we should be allowed to do so

[1672.919 - 1675.24] and then then there are other people

[1674.0 - 1676.88] that just really cringe at that and

[1675.24 - 1679.32] they're like no that like is an affront

[1676.88 - 1681.3600000000001] to you know God or whatever like if you

[1679.32 - 1683.799] change yourself then that's evil or

[1681.36 - 1685.1589999999999] whatever I don't know I remember like so

[1683.799 - 1688.36] here's the story that I'm thinking of I

[1685.159 - 1692.519] remember my stepbrother wanted to have

[1688.36 - 1696.1999999999998] jaw surgery to cure his overbite and his

[1692.519 - 1697.559] religious family like like like got

[1696.2 - 1700.32] really bent out of shape because it's

[1697.559 - 1702.8799999999999] like well God gave you that jaw and now

[1700.32 - 1705.48] your your desire to go through cosmetic

[1702.88 - 1708.2] surgery is an affront to God and it's

[1705.48 - 1709.84] like okay well I mean that that's them

[1708.2 - 1711.2] but you know people have an Impulse to

[1709.84 - 1714.84] control each other anyways I'm getting

[1711.2 - 1716.1200000000001] lost in a in a rabbit hole okay so I did

[1714.84 - 1717.48] promise that I would address this so

[1716.12 - 1720.12] This Is We're winding down the video

[1717.48 - 1722.32] what about aliens so there have been

[1720.12 - 1725.08] some recent disclosures and it's really

[1722.32 - 1726.9189999999999] difficult to think about like okay if

[1725.08 - 1729.6789999999999] any of the testimony that has been given

[1726.919 - 1731.6000000000001] to Congress which for some background uh

[1729.679 - 1733.799] was his name David grush and a few

[1731.6 - 1735.6789999999999] others have testified that like yes we

[1733.799 - 1737.399] have recovered non-human biological

[1735.679 - 1740.0] entities we have recovered

[1737.399 - 1741.76] extraterrestrial craft we have

[1740.0 - 1743.36] documented evidence of these craft that

[1741.76 - 1746.48] are able to do things that we cannot

[1743.36 - 1747.24] physically explain um mostly pertaining

[1746.48 - 1749.64] to

[1747.24 - 1750.919] acceleration uh and deceleration so it's

[1749.64 - 1754.2] like okay well how do they accelerate

[1750.919 - 1755.96] and decelerate that fast um so what is

[1754.2 - 1759.88] what is the scientific implication of

[1755.96 - 1762.519] this and one thing I want to say is like

[1759.88 - 1765.679] okay yes some of these things seem to be

[1762.519 - 1768.24] magical uh but just because you have a

[1765.679 - 1771.64] craft that defies the laws a physics as

[1768.24 - 1773.76] we know it doesn't mean that it is Magic

[1771.64 - 1775.5590000000002] or that it that also doesn't immediately

[1773.76 - 1778.32] translate to well because that's

[1775.559 - 1780.6] possible everything else is possible and

[1778.32 - 1782.559] so I want to leave you with a quote uh

[1780.6 - 1785.12] any sufficiently advanced technology is

[1782.559 - 1787.039] indistinguishable from Magic this was

[1785.12 - 1790.279] Arthur C Clark he called it his third

[1787.039 - 1791.64] law or whatever I guess um but here's an

[1790.279 - 1793.64] example that I want to leave you with

[1791.64 - 1796.48] think of your your cell phone your

[1793.64 - 1797.919] smartphone if you were to tell someone

[1796.48 - 1800.88] or show someone

[1797.919 - 1802.1200000000001] in the 1500s what a cell phone was and

[1800.88 - 1803.3600000000001] what it could do and the fact that you

[1802.12 - 1805.4399999999998] could literally call someone

[1803.36 - 1807.9599999999998] instantaneously on the other side of the

[1805.44 - 1811.559] planet um you would have been burned at

[1807.96 - 1813.72] the stake as a witch because that that

[1811.559 - 1817.2] technological capacity was just not

[1813.72 - 1820.24] within the realm of Consciousness until

[1817.2 - 1821.8400000000001] this last century now obviously the I

[1820.24 - 1823.72] guess the telegraph is over a century

[1821.84 - 1825.799] old and people started realizing that

[1823.72 - 1827.96] you could communicate vast different

[1825.799 - 1829.559] distances instantaneously

[1827.96 - 1830.919] so maybe a century ago you wouldn't have

[1829.559 - 1832.48] been burnt at the steak but certainly

[1830.919 - 1834.039] five centuries ago if you would have

[1832.48 - 1835.76] said oh yeah here's a magical device

[1834.039 - 1837.6] that has no physical connections to

[1835.76 - 1839.12] anything else and I can talk to someone

[1837.6 - 1840.76] on the other side of the planet you

[1839.12 - 1842.4799999999998] could even talk to people in space if

[1840.76 - 1844.559] you wanted to they would have literally

[1842.48 - 1848.2] burned you at at the stake because that

[1844.559 - 1851.799] is some devilry witchcraft stuff

[1848.2 - 1854.0800000000002] now to a mind 500 years ago your iPhone

[1851.799 - 1855.72] would have appeared to be pure magic but

[1854.08 - 1857.6789999999999] today we understand that it has very

[1855.72 - 1859.72] mundane explanations of electrical

[1857.679 - 1861.679] circuits and radio signals and once you

[1859.72 - 1864.24] have radio signals and and integrated

[1861.679 - 1867.0] circuits the rest is pretty much a a

[1864.24 - 1868.639] given but if you like there was a few

[1867.0 - 1870.039] comments on recent videos like just

[1868.639 - 1871.6789999999999] imagine trying to explain language

[1870.039 - 1873.6] models to someone 20 years ago and they

[1871.679 - 1876.24] would have been like what I don't get it

[1873.6 - 1879.039] so but today it has a very mundane

[1876.24 - 1882.279] explanation and so one thing that I want

[1879.039 - 1883.8799999999999] to just kind of really push back on is

[1882.279 - 1886.2] is just because you can imagine

[1883.88 - 1889.0390000000002] something and just because something

[1886.2 - 1890.919] seems magical to you today that doesn't

[1889.039 - 1894.08] mean that it is all that different or

[1890.919 - 1898.1200000000001] all that exotic and it it really comes

[1894.08 - 1901.36] down to perception and so yes like well

[1898.12 - 1903.799] Dave like you're saying like Okay so let

[1901.36 - 1905.24] me just unpack this you know there are

[1903.799 - 1907.1589999999999] things that we can't imagine being

[1905.24 - 1909.3990000000001] possible today that might be possible

[1907.159 - 1911.5590000000002] tomorrow and so like let's reverse that

[1909.399 - 1913.039] like okay so what is what is the iPhone

[1911.559 - 1914.519] 500 years from now that we can't

[1913.039 - 1917.1589999999999] possibly imagine

[1914.519 - 1919.84] today yes that kind of technological

[1917.159 - 1922.7600000000002] leap is possible but it's not

[1919.84 - 1925.8799999999999] necessarily going to be physics

[1922.76 - 1927.919] shattering uh especially as we learn

[1925.88 - 1929.72] more and more about science and physics

[1927.919 - 1931.96] and technology and we get those

[1929.72 - 1933.24] diminishing returns and I suspect that

[1931.96 - 1935.519] we're going to have a different

[1933.24 - 1938.159] orientation towards science and

[1935.519 - 1939.36] technology eventually and so this is

[1938.159 - 1941.0] something that kind of I've been

[1939.36 - 1943.6] thinking about is what happens when we

[1941.0 - 1945.12] get to a steady state world where it's

[1943.6 - 1948.24] just kind of a foregone conclusion that

[1945.12 - 1950.5189999999998] like yeah we do know 95% of all science

[1948.24 - 1952.48] out there and the last 5% is going to be

[1950.519 - 1954.96] really difficult and expensive to get

[1952.48 - 1957.3600000000001] but like the frontiers of scientific

[1954.96 - 1959.679] discovery might eventually be known kind

[1957.36 - 1961.4399999999998] of like the age of Discovery when we

[1959.679 - 1963.3600000000001] were sailing around the planet earth

[1961.44 - 1965.0800000000002] eventually all of planet Earth was known

[1963.36 - 1967.4799999999998] now granted there's you know infinite

[1965.08 - 1969.039] more planets out there to discover so I

[1967.48 - 1971.679] don't know let me know what you think in

[1969.039 - 1973.72] the comments like subscribe etc etc

[1971.679 - 1977.72] thanks for watching I hope this gave you

[1973.72 - 1977.72] some food for thought cheers