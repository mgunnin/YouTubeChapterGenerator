[1.02 - 4.92] morning everybody David Shapiro here

[3.179 - 6.359] with another video

[4.92 - 9.0] um this is actually a re-record because

[6.359 - 11.46] the um first one the audio wasn't good

[9.0 - 13.799] uh but before we get started I want to

[11.46 - 17.039] do just a little bit of housekeeping so

[13.799 - 19.858999999999998] first I'm starting a new mailing list

[17.039 - 22.199] um I was on I was on a MailChimp but

[19.859 - 23.580000000000002] it's too complicated for what I need

[22.199 - 26.880000000000003] um so I'm moving over to this Google

[23.58 - 29.339999999999996] form I've already got 48 responses

[26.88 - 32.16] um so this is for people primarily

[29.34 - 33.3] people who either want to invest in my

[32.16 - 35.279999999999994] startup

[33.3 - 37.26] um and or people who want to collaborate

[35.28 - 39.059] in some way or another

[37.26 - 40.62] um and then also if you just want uh

[39.059 - 42.839999999999996] generic news

[40.62 - 46.32] um links in the description

[42.84 - 49.5] um so that's that the other thing is

[46.32 - 51.6] um I did add ads I posted a poll and

[49.5 - 54.480000000000004] more than 90 percent of people were okay

[51.6 - 57.480000000000004] with ads that's perfectly fine but I'm

[54.48 - 61.26] over 5 000 subscribers now so if the 10

[57.48 - 63.48] of people who uh were willing to support

[61.26 - 66.36] me on patreon that's five times what I

[63.48 - 69.24] have now and if I if I 5x what I've got

[66.36 - 71.159] now that puts me at 5 000 a month and if

[69.24 - 72.96] I get to there I will take down ads

[71.159 - 75.06] permanently because that's enough to

[72.96 - 77.46] support my life

[75.06 - 80.34] um right now the combination of ads in

[77.46 - 82.32] patreon is enough to support me but

[80.34 - 84.24000000000001] um honestly I see ads as a waste of time

[82.32 - 86.82] I don't want to waste your time I want

[84.24 - 88.91999999999999] to add value so if we can get to that

[86.82 - 90.41999999999999] Mark uh great and I'm not going to do

[88.92 - 91.979] Partnerships because I'm not gonna I'm

[90.42 - 94.619] not gonna waste your time by putting

[91.979 - 96.96] sponsor ads in my videos as well I want

[94.619 - 99.659] to have as much value as possible with

[96.96 - 101.759] no distractions anyways offer still on

[99.659 - 103.38000000000001] the table if we can get to four or five

[101.759 - 106.759] thousand a month I will take down ads

[103.38 - 111.06] permanently now on with the show

[106.759 - 112.74] a i and uh this was a popular topic that

[111.06 - 114.18] has been requested in a bunch of

[112.74 - 115.79899999999999] different ways

[114.18 - 118.43900000000001] um people want to know how AI is going

[115.799 - 121.259] to affect them uh their jobs and that

[118.439 - 126.05999999999999] sort of thing so here we go how will

[121.259 - 127.439] Tech like chat GPT affect your life uh

[126.06 - 129.239] there are a lot of people that are

[127.439 - 131.819] concerned about it and for good reason

[129.239 - 133.5] we will unpack all of those reasons and

[131.819 - 135.23899999999998] we will look at data in the course of

[133.5 - 136.62] this video oh by the way it's long which

[135.239 - 139.5] you probably noticed when you clicked on

[136.62 - 142.86] it with the the length and the chapters

[139.5 - 145.44] all right first let's set the stage what

[142.86 - 147.78] is the context here if you are new to

[145.44 - 149.7] the channel which many of you are

[147.78 - 151.8] um you might you might have landed here

[149.7 - 154.61999999999998] and you don't know anything about

[151.8 - 156.59900000000002] AI or specifically this current wave of

[154.62 - 159.42000000000002] AI so

[156.599 - 162.54] the the current thing is the big

[159.42 - 165.0] breakthrough was called uh an llm or a

[162.54 - 167.4] large language model it's basically

[165.0 - 169.2] autocorrect on steroids

[167.4 - 172.58] um or another way I think of it as

[169.2 - 174.78] predictive text however it is like

[172.58 - 176.4] literally millions of times more

[174.78 - 177.9] powerful than the predictive text on

[176.4 - 179.34] your phone maybe billions of times it's

[177.9 - 182.459] very very powerful

[179.34 - 184.20000000000002] now this concept might seem simple

[182.459 - 187.26] you know if all it does is predict the

[184.2 - 189.54] next word okay like how is that so

[187.26 - 191.519] powerful I won't unpack all the reasons

[189.54 - 193.739] I've got other videos talking about uh

[191.519 - 195.72] this AI but it is very powerful

[193.739 - 199.5] especially if you can accurately predict

[195.72 - 202.379] the next word in any topic and the this

[199.5 - 205.019] this uh this ability has implications in

[202.379 - 208.01899999999998] Science Education technology law

[205.019 - 209.64000000000001] medicine basically everywhere so that's

[208.019 - 213.42000000000002] the context now that we've got the stage

[209.64 - 216.35999999999999] set why now what's different and why is

[213.42 - 220.26] AI suddenly taking off so fast

[216.36 - 222.84] well if you're new to llms to gpt3 and

[220.26 - 224.28] chat GPT uh it might surprise you to

[222.84 - 227.159] know that these technologies have been

[224.28 - 228.54] around for a few years gpt3 which this

[227.159 - 231.599] is based on has been around for two

[228.54 - 234.599] years so what changed what's different

[231.599 - 237.06] uh the primary thing that changed was

[234.599 - 241.2] the UI and the ux

[237.06 - 243.659] uh so chat is a very very intuitive and

[241.2 - 246.54] familiar interface Chad has been around

[243.659 - 248.879] for many years uh decades even

[246.54 - 251.819] um and uh you know everyone especially

[248.879 - 254.04] people my age will remember things like

[251.819 - 255.95899999999997] IRC and aim

[254.04 - 257.82] um but all you young people in your tick

[255.959 - 260.459] tocks these days I don't know how that

[257.82 - 263.15999999999997] works um anyways point being we're all

[260.459 - 266.52] familiar with text messages emails and

[263.16 - 268.5] chat interfaces and so when you have a

[266.52 - 271.5] powerful enough AI attached to a

[268.5 - 273.6] familiar interface people just get it so

[271.5 - 275.88] that's why that's why it's exploding

[273.6 - 277.97900000000004] suddenly after this technology has been

[275.88 - 279.54] on the stage for two years there is

[277.979 - 281.09999999999997] another component of that and that is

[279.54 - 283.38] fine tuning that is the reinforcement

[281.1 - 287.04] learning with human feedback that helped

[283.38 - 288.479] chat GPT produce such good answers we're

[287.04 - 291.3] not going to dive into that maybe I can

[288.479 - 294.65999999999997] make another video oh by the way

[291.3 - 297.72] um one of the best ways to to for me to

[294.66 - 299.46000000000004] find the content is y'all comment and

[297.72 - 301.259] vote and comment on each other's

[299.46 - 303.78] comments because that tells me what's

[301.259 - 305.699] resonating with you guys so uh if you

[303.78 - 307.67999999999995] whatever you want a video on comment in

[305.699 - 308.699] the videos tell me and talk to each

[307.68 - 313.86] other too

[308.699 - 315.78000000000003] okay so why chat though what is what is

[313.86 - 317.639] what's the underpinning thing like okay

[315.78 - 320.15999999999997] Chad is familiar but why

[317.639 - 322.919] why is it useful so it's simple and

[320.16 - 325.08000000000004] intuitive there's no bells and whistles

[322.919 - 328.139] and knobs and levers and complexity you

[325.08 - 330.479] don't need any code you have one place

[328.139 - 332.58] of interface you have a chat window you

[330.479 - 334.25899999999996] have a text box that you enter into it's

[332.58 - 337.139] brain dead simple you can't get it wrong

[334.259 - 339.96000000000004] it's also very flexible so if you've

[337.139 - 342.84000000000003] used Chad GPD you probably have noticed

[339.96 - 345.479] that like it can like role play it can

[342.84 - 347.34] tell you about history it can help you

[345.479 - 350.21999999999997] with coding with writing all kinds of

[347.34 - 352.979] stuff so it's a simple formula that

[350.22 - 356.34000000000003] applies to a lot of stuff so because

[352.979 - 358.62] it's so simple but flexible is it kind

[356.34 - 360.11999999999995] of like a universal tool an omni tool or

[358.62 - 361.88] a Swiss army knife and we'll get we'll

[360.12 - 364.919] get into that mentality in just a minute

[361.88 - 366.96] but for instance this is why automatic

[364.919 - 368.69899999999996] cars are more popular than manual cars

[366.96 - 371.58] because they're easier to use it's that

[368.699 - 375.3] simple so low friction high usability

[371.58 - 379.56] high flexibility this is a this is a a

[375.3 - 382.139] pillar of design moving forward of AI so

[379.56 - 384.06] just keep that in mind

[382.139 - 385.68] all right so all that being said what

[384.06 - 388.16] are its limitations give me a second I

[385.68 - 388.16] need some tea

[388.86 - 393.72] so the first limitation is that chat GPT

[391.8 - 396.3] and similar Technologies are not

[393.72 - 398.28000000000003] autonomous this is there's two reasons

[396.3 - 400.5] for this one it's by design for safety

[398.28 - 402.23999999999995] and two uh we haven't done quite enough

[400.5 - 403.979] work on cognitive architectures that's

[402.24 - 406.5] one of the things that I study and

[403.979 - 408.36] research and test if you're familiar

[406.5 - 409.5] with my older work on this channel and

[408.36 - 411.78000000000003] my books

[409.5 - 413.22] so it's not autonomous that means that

[411.78 - 415.25899999999996] humans are still in the driver's seat

[413.22 - 417.72] we've got our hands on the wheels we've

[415.259 - 419.52000000000004] got our our feet on the pedals

[417.72 - 421.56] um so we're still in control it just

[419.52 - 424.25899999999996] sits there and waits

[421.56 - 425.34] uh to a greater or lesser degree you

[424.259 - 427.259] also have to know what you're doing

[425.34 - 428.69899999999996] since you're steering

[427.259 - 431.22] excuse me

[428.699 - 433.139] um and because of that interacting with

[431.22 - 435.18] these models is a new skill it's an

[433.139 - 437.88] entirely new skill set I would not be

[435.18 - 440.58] surprised if within the month you see

[437.88 - 442.979] people saying like we want to have

[440.58 - 444.84] people you know on on your resume or you

[442.979 - 447.419] know on a job description you know how

[444.84 - 449.28] to interact with language models so and

[447.419 - 451.19899999999996] any anytime there's a new skill there's

[449.28 - 454.55999999999995] a new learning curve

[451.199 - 456.36] so another aspect of that you know it's

[454.56 - 459.9] not autonomous is the brain in a jar

[456.36 - 462.41900000000004] model uh chat gbt is not connected to

[459.9 - 464.28] the outside world at all rumor has it

[462.419 - 466.31899999999996] with uh their announcement of the chat

[464.28 - 467.4] GPT professional

[466.319 - 468.599] um they're gonna change that they're

[467.4 - 471.29999999999995] going to allow for some kind of

[468.599 - 473.21999999999997] integration to something

[471.3 - 474.539] um the most obvious thing seems it seems

[473.22 - 476.34000000000003] to be the internet and there's been

[474.539 - 478.62] plenty of people out there on YouTube

[476.34 - 480.84] doing experiments of connecting chat GPT

[478.62 - 482.34000000000003] to the internet and other stuff that's

[480.84 - 483.78] honestly why I haven't done a video on

[482.34 - 485.52] it I'm like oh someone already did that

[483.78 - 487.19899999999996] you don't I don't need to duplicate this

[485.52 - 490.02] effort

[487.199 - 491.34000000000003] um so Integrations are coming all kinds

[490.02 - 493.31899999999996] of people are working on it it would be

[491.34 - 495.35999999999996] silly if openai wasn't

[493.319 - 497.639] uh but for right now it's a brain and

[495.36 - 498.96000000000004] jar which means it's kind of just locked

[497.639 - 500.759] in its own head

[498.96 - 503.099] um it also can't do everything there's

[500.759 - 505.68] lots of gotchas and gaps and you know

[503.099 - 508.37899999999996] and things that it can't do well

[505.68 - 510.0] um again lots of people studying that uh

[508.379 - 511.91900000000004] doing there's lots of people tweeting

[510.0 - 513.599] about it other videos so I'm not going

[511.919 - 516.36] to cover that in depth but suffice to

[513.599 - 517.979] say chat GPT can't do everything it can

[516.36 - 520.38] do a lot though

[517.979 - 523.2] so let's talk about what it can do what

[520.38 - 525.18] is it really good at why is it so strong

[523.2 - 527.279] um it's like a Swiss army knife of AI

[525.18 - 529.38] tools it does a little bit of everything

[527.279 - 531.12] pretty good

[529.38 - 532.74] um and when I say everything I mean like

[531.12 - 535.38] almost everything it does a lot of

[532.74 - 537.66] things that you and I can't do just by

[535.38 - 538.98] virtue of we're one person

[537.66 - 541.38] um I had a recent interview with a

[538.98 - 543.72] professional prompt engineer Anna Bernie

[541.38 - 544.92] and you should look up that video and

[543.72 - 546.5400000000001] one of the things that she said is that

[544.92 - 548.279] working with language models is like

[546.54 - 550.68] working with a toddler who knows

[548.279 - 553.019] everything so the model knows just about

[550.68 - 554.6999999999999] everything but it can only follow simple

[553.019 - 556.8] instructions that's

[554.7 - 557.76] a very very shorthand version of what

[556.8 - 559.0799999999999] she meant

[557.76 - 560.76] um and I'm not trying to put words in

[559.08 - 562.8000000000001] her mouth but that's just like that that

[560.76 - 565.92] people have quoted that to me they're

[562.8 - 567.3] like oh man like she click anyways I

[565.92 - 568.74] don't want to get lost in the weeds that

[567.3 - 569.5799999999999] was that was a quotable moment from the

[568.74 - 572.1] video

[569.58 - 575.1] so for instance it can help with coding

[572.1 - 576.839] writing brainstorming it can teach you

[575.1 - 578.64] just about anything it can help you plan

[576.839 - 580.2] it can help you overcome writer's block

[578.64 - 582.0] right

[580.2 - 584.6400000000001] and it's so simple that pretty much

[582.0 - 587.64] everyone can use it and lastly it's very

[584.64 - 590.9399999999999] cheap right it talk it costs just a few

[587.64 - 593.04] cents maybe a dollar an hour to use and

[590.94 - 595.5] so one thing that I want to point out is

[593.04 - 598.3199999999999] that um and we'll we'll get into this uh

[595.5 - 600.839] later think about how much it would cost

[598.32 - 603.48] to pay an assistant to do the things

[600.839 - 605.0400000000001] that chat GPT does for you right and

[603.48 - 607.5600000000001] that's where you see oh that's where the

[605.04 - 611.06] value is it's way cheaper than a human

[607.56 - 613.4399999999999] and just as good as a team of 10 humans

[611.06 - 615.3] all right so now let's look at the data

[613.44 - 617.8800000000001] we've set the stage

[615.3 - 619.56] you understand what's going on and why

[617.88 - 622.08] it's valuable

[619.56 - 624.3] so where is going from here now I need

[622.08 - 625.5] to warn you we're going to go way back

[624.3 - 628.14] in history because we're going to

[625.5 - 631.14] establish long-term trends to understand

[628.14 - 633.66] and unpack what's happening where are we

[631.14 - 637.26] and where are we going

[633.66 - 638.76] okay I promise we're going way back

[637.26 - 641.3389999999999] we'll start at the first Industrial

[638.76 - 643.14] Revolution uh so basically started with

[641.339 - 645.6600000000001] the steam engine invented by this dude

[643.14 - 648.3] uh named James Watt James Watt something

[645.66 - 650.8199999999999] what I think it was James Watt uh the

[648.3 - 653.76] steam engine caused a huge shift towards

[650.82 - 655.98] urbanization because suddenly there are

[653.76 - 657.6] these machines that won they weren't

[655.98 - 660.3000000000001] that portable at first they had to be in

[657.6 - 662.519] giant Factory floors but you could hook

[660.3 - 665.279] up all kinds of fun stuff to it like

[662.519 - 667.62] looms and Mills and blah blah and you no

[665.279 - 669.8389999999999] longer were dependent upon water wheels

[667.62 - 672.36] and so then you could have a lot of

[669.839 - 674.94] power wherever you wanted it and so the

[672.36 - 677.04] steam engine filled an energetic Gap

[674.94 - 679.6800000000001] and what I mean by that is that human

[677.04 - 681.899] bodies are not that good at doing labor

[679.68 - 683.579] that's why we've used horses and ox and

[681.899 - 685.62] other beasts of burden in India they've

[683.579 - 688.92] used elephants for many years because

[685.62 - 691.5] they're large and stronger and that's

[688.92 - 693.779] why we have used uh farm animals since

[691.5 - 696.899] forever to do stuff and the steam engine

[693.779 - 698.64] takes that and turns it up to 11 because

[696.899 - 701.399] all you have to feed a steam engine is

[698.64 - 704.76] coal or wood and water and suddenly it

[701.399 - 707.519] can do the work of many many like Rivers

[704.76 - 710.459] worth of water wheels or many horses or

[707.519 - 712.519] many Ox worth of Labor and it doesn't

[710.459 - 715.8599999999999] get sick and die

[712.519 - 717.54] so the efficiency is there because of

[715.86 - 720.1800000000001] the amount of energy that it can put

[717.54 - 721.92] into things Chad GPT doesn't put energy

[720.18 - 723.8389999999999] into things it puts mental labor into

[721.92 - 725.579] things but it's all different kinds of

[723.839 - 728.1] Labor so there's mechanical energy

[725.579 - 730.38] there's mental energy and so on so just

[728.1 - 732.0600000000001] keep that in mind as we move up and

[730.38 - 734.519] forward into the future

[732.06 - 736.5] so this started in the uh 18th century

[734.519 - 739.5600000000001] in the 1700s

[736.5 - 743.22] okay so fast forward 100 years as the

[739.56 - 745.6199999999999] steam engine is uh really ramping up

[743.22 - 747.36] um we are starting to get uh mechanized

[745.62 - 749.16] agriculture which leads to the

[747.36 - 751.5] Agricultural Revolution

[749.16 - 754.019] so and then you combine that with crop

[751.5 - 756.72] science uh which really kind of started

[754.019 - 758.04] um who was it the like the someone who's

[756.72 - 759.899] considered like the father of crop

[758.04 - 764.399] science I think that was around 1920.

[759.899 - 767.82] anyways point being is uh around 1840 70

[764.399 - 771.06] percent of Americans were farmers

[767.82 - 772.5600000000001] so the mechanization of farming has

[771.06 - 775.38] completely destroyed this as a job

[772.56 - 777.3] sector now less than two percent are

[775.38 - 781.079] around two percent of Americans are

[777.3 - 782.76] farmers so farm jobs were destroyed but

[781.079 - 784.62] of course everyone will say like oh but

[782.76 - 786.12] you know technology disruptions create

[784.62 - 788.0600000000001] more jobs and we'll talk about that in

[786.12 - 790.8] the next slide but point being is

[788.06 - 793.6199999999999] sometimes a technology shift does

[790.8 - 795.5999999999999] permanently destroy a sector right keep

[793.62 - 798.18] that in mind is that mechanization

[795.6 - 800.4590000000001] pretty much permanently killed farming

[798.18 - 802.019] as a major sector of the economy that

[800.459 - 804.899] being said there are still Farmers today

[802.019 - 808.86] right there's just a much fewer Farmers

[804.899 - 812.519] overall as a percentage of the workforce

[808.86 - 816.0] okay so then let's fast forward to

[812.519 - 818.1] um so this is this is 1840 to well 2000

[816.0 - 822.779] so almost present so let's fast forward

[818.1 - 825.0600000000001] to here the last uh 80 years or so the

[822.779 - 828.899] post-war boom so what happened during

[825.06 - 832.8599999999999] World War II was a tremendous investment

[828.899 - 835.26] in science and technology not only that

[832.86 - 837.48] um women entered the workforce in Mass

[835.26 - 839.22] because all the men were either sent to

[837.48 - 841.74] the front or were doing things that only

[839.22 - 844.98] men can do and so women were brought

[841.74 - 847.5790000000001] into the workforce to do typing to do uh

[844.98 - 850.139] Computing to do uh weapons assembly

[847.579 - 852.3] garment manufacturing all kinds of stuff

[850.139 - 855.12] and so one of the unintended

[852.3 - 858.12] consequences of World War II was first

[855.12 - 859.68] the workforce changed drastically once

[858.12 - 861.54] women got into the workforce they're

[859.68 - 862.92] like we don't want to go back home we

[861.54 - 864.779] want to stay in the workforce we like

[862.92 - 867.0] having money and having our own

[864.779 - 869.519] determination so that was a permanent

[867.0 - 872.279] societal shift but then

[869.519 - 876.36] because of the huge advance in science

[872.279 - 878.7] and technology we had a huge boost to a

[876.36 - 880.74] huge shift sorry to a service-based

[878.7 - 883.22] economy or a knowledge-based economy and

[880.74 - 887.339] that's what this graph shows so we have

[883.22 - 889.86] non-farm employees which is uh like

[887.339 - 893.22] service sector right or um or

[889.86 - 896.82] non-manufacturing right so Manufacturing

[893.22 - 899.4590000000001] Services Farm the whole economy shifted

[896.82 - 902.1] so if you remember this this one farm

[899.459 - 903.8389999999999] jobs going down service jobs and

[902.1 - 907.26] knowledge jobs going up so that's been

[903.839 - 909.6600000000001] the last Almost whole Century now

[907.26 - 913.199] um so we have a century of uh the

[909.66 - 914.9399999999999] post-war boom because of uh doing no

[913.199 - 916.9799999999999] small part due to mechanization right

[914.94 - 921.0] and then it only ramped up from there

[916.98 - 922.62] because here in 1959 and so on this is

[921.0 - 926.16] when you start introducing computers

[922.62 - 930.54] which leads to the information age

[926.16 - 932.3389999999999] so remember how I showed you that uh

[930.54 - 934.3199999999999] mechanization as you mentioned the

[932.339 - 936.899] internal combustion engine

[934.32 - 939.779] um basically destroyed farming as a

[936.899 - 942.36] primary staple of the economy

[939.779 - 944.9399999999999] um and but then what happens is you get

[942.36 - 946.98] new sectors you get one sector that

[944.94 - 949.019] pretty much goes away like

[946.98 - 950.76] um uh horse groomers right and horse

[949.019 - 952.94] drivers that went away because of the

[950.76 - 955.62] Ford Model T and and Automobiles

[952.94 - 956.6990000000001] likewise you get new things right so we

[955.62 - 958.5] replaced

[956.699 - 960.5999999999999] um people care for horses with auto

[958.5 - 962.76] mechanics and auto builders

[960.6 - 965.16] likewise the introduction of computers

[962.76 - 968.76] led to the information age which created

[965.16 - 970.38] an entirely new sector of I.T and and

[968.76 - 972.66] computer Engineers that's what I have

[970.38 - 974.82] done for the last 15 years of my career

[972.66 - 977.76] until I just retired because now I'm

[974.82 - 979.5] making enough money on uh on ads and

[977.76 - 982.38] patreon

[979.5 - 984.3] um and so again like this is another

[982.38 - 986.3389999999999] perfect example I couldn't have switched

[984.3 - 987.4799999999999] to this job before YouTube right before

[986.339 - 991.139] the internet

[987.48 - 993.4200000000001] and so technology will sometimes destroy

[991.139 - 995.639] sectors or greatly reduce them but then

[993.42 - 1000.639] it will also create entirely new

[995.639 - 1000.639] categories so the theory is

[1000.8 - 1007.2199999999999] um oh sorry premature the theory is that

[1003.92 - 1010.16] uh as uh technology and science Advance

[1007.22 - 1012.5600000000001] yes some categories will go away or be

[1010.16 - 1014.54] diminished but new categories will be

[1012.56 - 1016.88] created and those new categories will

[1014.54 - 1020.12] inevitably be larger than the previous

[1016.88 - 1021.74] ones now I want to temper this by

[1020.12 - 1024.319] pointing out that in that same time

[1021.74 - 1026.9] period where we see farm jobs going the

[1024.319 - 1028.52] way of the dinosaurs and service jobs

[1026.9 - 1031.939] going up

[1028.52 - 1033.799] population has also exploded right so

[1031.939 - 1036.919] some of what you're seeing is a function

[1033.799 - 1040.339] of population growth some of it is also

[1036.919 - 1043.76] a function of of Technology of

[1040.339 - 1047.1789999999999] immigration of science but one thing to

[1043.76 - 1050.36] point out is that population growth has

[1047.179 - 1052.88] been a huge driver of economic growth

[1050.36 - 1055.6399999999999] more more workers more producers and

[1052.88 - 1059.2990000000002] more consumers economy grows

[1055.64 - 1061.22] if the economy is flat or declines

[1059.299 - 1064.1] in in most Nations where that has

[1061.22 - 1066.38] happened the economy also stalls look at

[1064.1 - 1068.24] Italy look at Japan look at Greece right

[1066.38 - 1070.4] you look around the world to where the

[1068.24 - 1073.58] population has plateaued and has

[1070.4 - 1076.64] contracted and so has their economy so

[1073.58 - 1078.6789999999999] correlation does not equal causation but

[1076.64 - 1080.3600000000001] it's a really compelling argument so

[1078.679 - 1082.52] just keep all that in mind that all

[1080.36 - 1084.26] these growth narratives around you know

[1082.52 - 1086.48] Science and Technology only causes

[1084.26 - 1088.34] growth I don't know that I've in fully

[1086.48 - 1090.98] agree with that I think that population

[1088.34 - 1092.84] growth has been a primary driver of

[1090.98 - 1094.76] economic growth for the last few

[1092.84 - 1097.1] centuries especially when you consider

[1094.76 - 1099.44] that we hit our fastest period of

[1097.1 - 1100.76] population growth in like the 50s

[1099.44 - 1103.3400000000001] um and it started slowing down because

[1100.76 - 1105.74] we're reaching carrying capacity okay

[1103.34 - 1108.08] but the conclusion that the economists

[1105.74 - 1110.1200000000001] want you to come to right now

[1108.08 - 1112.3999999999999] is that new technology always creates

[1110.12 - 1115.6399999999999] new jobs yes it destroys some categories

[1112.4 - 1118.7] but it creates new categories and growth

[1115.64 - 1120.7990000000002] is infinite hypothetically

[1118.7 - 1122.179] I beg to differ so now we're going to

[1120.799 - 1124.16] Pivot and talk about the evidence

[1122.179 - 1127.2800000000002] against this narrative that technology

[1124.16 - 1129.98] only creates new jumps so first of all

[1127.28 - 1133.94] we are here

[1129.98 - 1135.559] this is this is a uh um this is uh as we

[1133.94 - 1138.38] approach the carrying capacity of the

[1135.559 - 1141.02] planet which is suspected to be around 9

[1138.38 - 1142.5800000000002] to 11 billion maybe up to 13 billion

[1141.02 - 1144.02] with some more technological

[1142.58 - 1147.559] improvements

[1144.02 - 1149.299] um we are going to start uh entering

[1147.559 - 1151.58] into a phase of what's called economic

[1149.299 - 1153.679] compaction now this is a term that I

[1151.58 - 1155.4189999999999] have very rarely seen it's kind of a

[1153.679 - 1157.94] very Arcane term and I couldn't even

[1155.419 - 1160.8200000000002] find uh some something defining this

[1157.94 - 1163.22] again but I do remember reading about it

[1160.82 - 1165.98] and so economic compaction is basically

[1163.22 - 1169.52] there are more workers competing for

[1165.98 - 1171.14] fewer resources including jobs right and

[1169.52 - 1173.179] we're also going to be approaching the

[1171.14 - 1175.5800000000002] thermodynamic limits of things like

[1173.179 - 1177.679] hydrological Cycles there's only so much

[1175.58 - 1179.24] fresh water to go around there's only so

[1177.679 - 1182.24] much light to go around there's only so

[1179.24 - 1185.6] much arable land around and as we expand

[1182.24 - 1187.4] as a species to maximum capacity of our

[1185.6 - 1189.62] environment because we haven't gotten

[1187.4 - 1191.3600000000001] off Earth yet and oh by the way there is

[1189.62 - 1193.52] there is no other fertile soil in this

[1191.36 - 1196.82] entire solar system so Earth is all we

[1193.52 - 1199.28] got so we are we are presently facing

[1196.82 - 1202.1599999999999] the early stages of economic compaction

[1199.28 - 1204.9189999999999] which is basically it's getting crowded

[1202.16 - 1206.8400000000001] and we knew this whether or not we would

[1204.919 - 1209.6000000000001] admit it to ourselves we watch movies

[1206.84 - 1211.3999999999999] like The Matrix and Blade Runner

[1209.6 - 1213.02] um where like we have these dystopian

[1211.4 - 1215.179] visions of the future where everyone is

[1213.02 - 1216.799] living on top of each other and like

[1215.179 - 1219.02] we're afraid of that like we nobody

[1216.799 - 1220.52] wants to live like that but we kind of

[1219.02 - 1222.2] intuitively know that's where we're

[1220.52 - 1224.96] heading

[1222.2 - 1226.64] um and so again when you zoom out and

[1224.96 - 1228.8600000000001] look at the planet as a whole I don't

[1226.64 - 1231.44] care about macroeconomic Trends look at

[1228.86 - 1233.0] the total energy available to the human

[1231.44 - 1235.039] species look at the total amount of

[1233.0 - 1237.26] water and land available to the human

[1235.039 - 1238.64] species that's what I see driving the

[1237.26 - 1242.419] trends right now

[1238.64 - 1245.0590000000002] now if economic growth has been tightly

[1242.419 - 1246.8600000000001] correlated with population growth then

[1245.059 - 1249.86] economic growth is probably about to

[1246.86 - 1252.74] taper off and Plateau globally within

[1249.86 - 1255.1599999999999] the next 10 to 20 30 50 years who knows

[1252.74 - 1259.7] but pretty soon

[1255.16 - 1261.8600000000001] okay so if that previous narrative that

[1259.7 - 1264.02] new technology always creates new jobs

[1261.86 - 1265.6999999999998] and new categories you would expect the

[1264.02 - 1268.8799999999999] total employment to continue going up

[1265.7 - 1271.94] through the end of the 20th 20th century

[1268.88 - 1274.5800000000002] and into the 21st century that's not

[1271.94 - 1277.46] true that's not what happened labor

[1274.58 - 1280.9399999999998] force participation rate peaked in the

[1277.46 - 1283.22] year 2000. let me say that again the the

[1280.94 - 1285.6200000000001] the period of time where we had the most

[1283.22 - 1288.5] participation in the in the in the labor

[1285.62 - 1291.26] market in America was in the year 2000

[1288.5 - 1294.5] right at the beginning of the.com

[1291.26 - 1297.26] Revolution right at the beginning of the

[1294.5 - 1300.44] the technology uh the shift towards you

[1297.26 - 1303.14] know you know the singularity so

[1300.44 - 1305.659] there's obviously this is this is this

[1303.14 - 1307.76] is uh there's lots of variables lots of

[1305.659 - 1309.6200000000001] factors they go into this

[1307.76 - 1312.02] and so I'm not saying that that

[1309.62 - 1314.84] automation or technology alone is

[1312.02 - 1317.0] responsible for this but if that

[1314.84 - 1319.4599999999998] previous narrative was true the

[1317.0 - 1322.159] technology always creates new categories

[1319.46 - 1326.0] which always result in growth

[1322.159 - 1328.7600000000002] then you'd expect to not see a 23-year

[1326.0 - 1331.46] downward Trend in labor force

[1328.76 - 1333.3799999999999] participation because theoretically the

[1331.46 - 1335.48] demand for jobs the demand for workers

[1333.38 - 1337.5200000000002] would be so compelling that the salaries

[1335.48 - 1338.96] would be so good that people would be

[1337.52 - 1341.12] like you know what it's worth my time

[1338.96 - 1343.1000000000001] but instead we have the opposite Trend

[1341.12 - 1344.6589999999999] we have quiet quitting we have the great

[1343.1 - 1346.9399999999998] resignation which I'm now a part of

[1344.659 - 1348.8600000000001] because I was like you know what my day

[1346.94 - 1352.3600000000001] job isn't worth it I'm gonna go make

[1348.86 - 1352.36] YouTube videos instead and

[1352.84 - 1356.6789999999999] that's the first time I said that out

[1354.98 - 1360.6200000000001] loud and wow

[1356.679 - 1362.0590000000002] anyways so point being a lot of us are

[1360.62 - 1363.6789999999999] checking out of the uh out of the

[1362.059 - 1366.5] conventional economy because we're just

[1363.679 - 1368.0590000000002] like nah it's not worth it

[1366.5 - 1370.82] um if

[1368.059 - 1374.12] you know if if my salary had gone up

[1370.82 - 1376.039] like and locked up with the value that I

[1374.12 - 1378.4399999999998] was adding my day job should have paid

[1376.039 - 1380.12] me like 200 000 a year but it didn't

[1378.44 - 1382.1000000000001] right

[1380.12 - 1383.7199999999998] um like I'm a freaking expert and I'm

[1382.1 - 1386.1789999999999] like I can go make more money on YouTube

[1383.72 - 1387.98] what I dealing why am I dealing with you

[1386.179 - 1390.14] bozos anyways sorry I'm getting lost in

[1387.98 - 1393.32] the weeds point being is it's not

[1390.14 - 1395.3600000000001] working that the theory that uh

[1393.32 - 1397.9399999999998] technology and science creates new jobs

[1395.36 - 1400.039] and new categories we have a 23-year

[1397.94 - 1402.679] trend saying the opposite

[1400.039 - 1405.74] now let's look at some more data

[1402.679 - 1407.96] um so I need to inform you of two

[1405.74 - 1409.4] categories uh one is neat and the other

[1407.96 - 1411.02] is nilf

[1409.4 - 1413.179] um and no get your mind out of the

[1411.02 - 1414.32] gutter I am a nilf i that means not in

[1413.179 - 1415.3400000000001] labor force

[1414.32 - 1417.2] um although

[1415.34 - 1419.72] since I'm starting a startup maybe I am

[1417.2 - 1422.419] in the labor force I'm just yeah I don't

[1419.72 - 1424.22] know uh anyways point being uh neat

[1422.419 - 1427.2800000000002] means not seeking education employment

[1424.22 - 1430.82] or training so anit is someone who

[1427.28 - 1432.559] um who has just never like I think it's

[1430.82 - 1434.299] typically young people but these are

[1432.559 - 1436.28] people that are just never ever going to

[1434.299 - 1439.28] even enter the workforce in the first

[1436.28 - 1442.1] place and then anilf is someone who has

[1439.28 - 1444.5] checked out for whatever reason

[1442.1 - 1447.559] um whether it's a disability or

[1444.5 - 1449.419] voluntary choice or freelancing or

[1447.559 - 1451.039] whatever actually I don't know I don't

[1449.419 - 1454.2800000000002] know if freelancing is is counted in

[1451.039 - 1456.5] that so maybe maybe I'm not enough sorry

[1454.28 - 1458.6589999999999] um long story short people are checking

[1456.5 - 1460.46] out of work and so let's let's just

[1458.659 - 1463.4] unpack this graph real quick because

[1460.46 - 1465.799] this is small so this is the same data

[1463.4 - 1467.8400000000001] we saw a minute ago which is the um the

[1465.799 - 1470.059] labor force participation rate and so

[1467.84 - 1472.1] you see it followed this big hump peaked

[1470.059 - 1473.059] around 2000 and it's been downhill ever

[1472.1 - 1476.4189999999999] since

[1473.059 - 1478.82] then this blue line is the uh is the

[1476.419 - 1481.4] ratio of not in labor force

[1478.82 - 1484.22] um so we have today it looks like we're

[1481.4 - 1485.7800000000002] approaching 96 million people

[1484.22 - 1488.72] um in America that are not in the labor

[1485.78 - 1491.6589999999999] force and this trend is not slowing down

[1488.72 - 1493.28] so again that narrative that the

[1491.659 - 1495.919] information age is going to

[1493.28 - 1498.32] revolutionize everything doesn't seem

[1495.919 - 1500.2990000000002] like it's happening so the new

[1498.32 - 1502.9399999999998] conclusion that I've come to based on a

[1500.299 - 1504.799] 23-year trend is the information age is

[1502.94 - 1506.9] not producing more jobs or abundance of

[1504.799 - 1510.32] demand for workers certainly not enough

[1506.9 - 1511.52] demand to have salaries rise in a in a

[1510.32 - 1514.46] fashion that would be compelling enough

[1511.52 - 1516.5] to reverse the trend of people checking

[1514.46 - 1517.88] out permanently well I don't know if

[1516.5 - 1520.46] it's permanent but people checking out

[1517.88 - 1522.38] seemingly permanently obviously like if

[1520.46 - 1524.8400000000001] you go for 23 years without a job like

[1522.38 - 1528.5] you got something else going on

[1524.84 - 1530.6] so let's talk about who's at risk if I I

[1528.5 - 1533.539] hope this provides a compelling enough

[1530.6 - 1536.299] uh argument that like okay that old

[1533.539 - 1539.84] narrative isn't holding up so who's at

[1536.299 - 1542.24] risk according to this zippya uh uh link

[1539.84 - 1546.3799999999999] which has a lot more graphs

[1542.24 - 1548.72] um we've got 25 of the population is at

[1546.38 - 1553.1000000000001] high potential uh for being automated

[1548.72 - 1555.2] away and another 35 almost 36 percent is

[1553.1 - 1557.6] at medium potential so that means the

[1555.2 - 1560.059] vast majority of workers today are at

[1557.6 - 1562.6999999999998] medium or high risk

[1560.059 - 1565.22] for being automated out of their jobs

[1562.7 - 1567.44] it's happening

[1565.22 - 1569.24] um so like

[1567.44 - 1571.5800000000002] you might the the first thing is like

[1569.24 - 1572.6] okay how do I protect myself from that

[1571.58 - 1575.62] um

[1572.6 - 1575.62] they the the

[1577.1 - 1582.02] there's a few things that can protect

[1578.96 - 1584.0] people so one manual labor does take a

[1582.02 - 1585.98] little bit longer to automate and the

[1584.0 - 1588.5] reason is because robots are not yet

[1585.98 - 1589.94] what's called compliant so a compliant

[1588.5 - 1592.22] robot here actually let me make sure

[1589.94 - 1594.679] that okay yes we're recording correctly

[1592.22 - 1596.419] okay uh so a compliant robot is

[1594.679 - 1599.539] something that if you push on it it can

[1596.419 - 1601.7] kind of adapt to Dynamic forces and

[1599.539 - 1605.12] pressures the leading company

[1601.7 - 1606.5] um uh building uh compliant robots can

[1605.12 - 1609.32] you guess who it is it's actually Disney

[1606.5 - 1612.32] because Disney has said animatronics for

[1609.32 - 1614.539] many many years and so ironically enough

[1612.32 - 1616.76] Disney might make the first fully

[1614.539 - 1618.799] compliant robot that's able to like do

[1616.76 - 1620.6589999999999] dishes with you in your kitchen

[1618.799 - 1621.98] um who knows we'll see

[1620.659 - 1623.9] um but

[1621.98 - 1627.08] human touch and emotional intelligence

[1623.9 - 1628.179] are critical and those might never be

[1627.08 - 1632.8999999999999] replaced

[1628.179 - 1635.779] so like for instance human touch is is

[1632.9 - 1639.0800000000002] not just um physical touch it can be you

[1635.779 - 1641.419] know caregiving for uh for for children

[1639.08 - 1644.4189999999999] um but also uh voice and emotional

[1641.419 - 1647.24] intelligence and communication uh so

[1644.419 - 1650.8400000000001] things like managers uh and and

[1647.24 - 1654.32] therapists and massage uh Specialists

[1650.84 - 1656.6589999999999] physical therapists doctors nurses a lot

[1654.32 - 1659.4189999999999] of jobs will be insulated against

[1656.659 - 1661.279] um robotic automation uh some of them

[1659.419 - 1663.44] indefinitely some jobs are just

[1661.279 - 1666.679] permanently and intrinsically better

[1663.44 - 1669.559] done by humans now if you work in front

[1666.679 - 1671.0590000000002] of a computer your job is in danger of

[1669.559 - 1672.74] being automated like simple rule of

[1671.059 - 1675.6789999999999] thumb if you work in front of a computer

[1672.74 - 1677.659] you can be automated away and I'm saying

[1675.679 - 1680.0590000000002] this as a YouTube Creator it's not going

[1677.659 - 1684.3400000000001] to be long until someone can just use an

[1680.059 - 1686.72] algorithm to synthesize voice face

[1684.34 - 1688.279] automatically come up with the slides

[1686.72 - 1690.679] that I'm doing and all all kinds of

[1688.279 - 1693.799] stuff like if it's if your product is

[1690.679 - 1697.7] video or text or email or audio like

[1693.799 - 1700.1] you're in danger of being automated away

[1697.7 - 1702.2] um now that being said those that can

[1700.1 - 1704.6589999999999] create and use AI tools are going to be

[1702.2 - 1706.5800000000002] the safest among knowledge workers which

[1704.659 - 1709.279] is one reason that I have pivoted my

[1706.58 - 1711.559] career away from it infrastructure and

[1709.279 - 1712.76] into AI I was like you know what AI is

[1711.559 - 1714.559] the next big thing so I'm going to

[1712.76 - 1716.12] become an expert on that okay enough

[1714.559 - 1718.34] said

[1716.12 - 1720.4399999999998] so automation has already destroyed jobs

[1718.34 - 1722.36] there was a graph that I that I was

[1720.44 - 1723.44] trying to find that it was like you know

[1722.36 - 1725.4799999999998] it was like

[1723.44 - 1727.64] um automation has created 58 million

[1725.48 - 1729.559] jobs in the last 10 years it's also

[1727.64 - 1731.3600000000001] destroyed 75 million jobs so we have a

[1729.559 - 1732.6789999999999] net loss of 15 million jobs or something

[1731.36 - 1734.6589999999999] like that

[1732.679 - 1736.1000000000001] um but I couldn't find that graph but I

[1734.659 - 1739.94] did find one that shows that we're going

[1736.1 - 1743.059] to lose 73 million more jobs by 2030. uh

[1739.94 - 1746.539] so it's like okay what happens when 73

[1743.059 - 1748.52] million more people lose their jobs and

[1746.539 - 1751.4] that trend of people checking out of the

[1748.52 - 1753.74] workforce seemingly for good continues

[1751.4 - 1755.9] and ramps up uh are we going to end up

[1753.74 - 1757.22] with a labor participation rate of less

[1755.9 - 1758.659] than 50 percent

[1757.22 - 1760.279] what are the rest of us going to do how

[1758.659 - 1761.8400000000001] are we going to make ends meet

[1760.279 - 1764.899] we'll get to that

[1761.84 - 1767.36] the the most Salient question after all

[1764.899 - 1770.2399999999998] this is why not hire humans if

[1767.36 - 1772.8799999999999] technology increases efficiency why not

[1770.24 - 1775.94] hire more humans the reason is because

[1772.88 - 1778.5200000000002] machines are often cheaper faster and

[1775.94 - 1782.059] better than humans they don't require

[1778.52 - 1784.279] insurance no HR they don't form unions

[1782.059 - 1786.3799999999999] so essentially machines are the perfect

[1784.279 - 1790.279] employee if they break you just fix it

[1786.38 - 1793.8200000000002] they only run on programming and Power

[1790.279 - 1796.399] excuse me uh so because of that humans

[1793.82 - 1798.74] are just expensive to employ so I need

[1796.399 - 1800.7199999999998] some tea

[1798.74 - 1803.6] humans are expensive that's all it comes

[1800.72 - 1806.48] down to machines are cheaper

[1803.6 - 1810.1399999999999] um chat GPT costs a few dollars per hour

[1806.48 - 1813.559] and can replace all kinds of uh human

[1810.14 - 1815.8400000000001] labor already just just think about how

[1813.559 - 1818.24] much help chat GT can give you it's

[1815.84 - 1821.24] basically an executive assistant and a

[1818.24 - 1823.1] sidekick all rolled up into one and it

[1821.24 - 1825.32] knows everything so it's like how many

[1823.1 - 1828.02] people would you have how big of a team

[1825.32 - 1830.899] would you have to have to replace that

[1828.02 - 1832.94] labor and how expensive would it be so

[1830.899 - 1834.02] and this is only version one of chat GPT

[1832.94 - 1835.76] folks

[1834.02 - 1837.3799999999999] think of how about powerful this is

[1835.76 - 1840.14] going to be a year from now two years

[1837.38 - 1841.94] from now three years from now

[1840.14 - 1843.5800000000002] one thing to keep in mind and we're

[1841.94 - 1846.02] about to Pivot this video in a big way

[1843.58 - 1847.9399999999998] capitalism is the Quest for maximum

[1846.02 - 1849.98] efficiencies and humans are not that

[1847.94 - 1851.779] efficient that's why we moved to the

[1849.98 - 1853.46] steam engine that's why we built

[1851.779 - 1856.039] computers that's why we built tractors

[1853.46 - 1858.02] that's why we build machines in the

[1856.039 - 1859.8799999999999] first place why we build tools and

[1858.02 - 1861.62] that's why they are valuable despite how

[1859.88 - 1864.38] expensive they are and how difficult

[1861.62 - 1867.9799999999998] they are to build even as complex as a

[1864.38 - 1869.179] computer is the value added is so

[1867.98 - 1871.7] compelling

[1869.179 - 1874.039] and the efficiency is so compelling that

[1871.7 - 1876.38] it's easier and cheaper in the long run

[1874.039 - 1877.46] to use a machine than it is to use a

[1876.38 - 1879.3200000000002] human

[1877.46 - 1881.059] this principle is only going to

[1879.32 - 1882.3799999999999] accelerate

[1881.059 - 1883.94] okay

[1882.38 - 1885.98] that's a lot of Doom and Gloom so what's

[1883.94 - 1887.779] next what do we do like are we all

[1885.98 - 1888.919] screwed is there hope

[1887.779 - 1891.02] um and it seems like there's a big

[1888.919 - 1892.46] Paradox right if efficiency keeps going

[1891.02 - 1894.62] up and I should have had a chart for

[1892.46 - 1897.98] that in terms of like productivity per

[1894.62 - 1900.6789999999999] per labor hour I think the I think on

[1897.98 - 1902.779] average the the average labor is like 80

[1900.679 - 1905.299] percent more per 80 times more

[1902.779 - 1908.059] productive than they were a century ago

[1905.299 - 1909.98] if we are 80 times more productive than

[1908.059 - 1912.559] we were a century ago where is all that

[1909.98 - 1914.48] going where is all that value that we're

[1912.559 - 1915.98] creating where is it going

[1914.48 - 1918.74] um and what can we do about it will this

[1915.98 - 1923.3600000000001] trend ever reverse

[1918.74 - 1926.6] so to answer that question we have to

[1923.36 - 1931.1589999999999] take a little detour into philosophy and

[1926.6 - 1933.559] ethics and religion uh and and economics

[1931.159 - 1936.3200000000002] but digress I repeat myself

[1933.559 - 1939.82] um so John Maynard Keynes who is the

[1936.32 - 1943.22] father of macroeconomics said in the

[1939.82 - 1946.82] 1920s or 30s that we would be we should

[1943.22 - 1948.34] be working around 10 to 14 hours per

[1946.82 - 1951.4399999999998] week by now

[1948.34 - 1954.5] uh we're not in fact we're working more

[1951.44 - 1957.2] well no I think I think uh total total

[1954.5 - 1958.64] labor hours peaked in the 70s or 80s

[1957.2 - 1959.8990000000001] um but we're still working a lot more

[1958.64 - 1963.0800000000002] than we should be

[1959.899 - 1965.059] uh and so where did this come from

[1963.08 - 1966.98] so

[1965.059 - 1968.84] this would take a really long time to

[1966.98 - 1970.22] unpack so I'll just recommend the book

[1968.84 - 1972.98] do nothing

[1970.22 - 1974.96] um which is very very well cited

[1972.98 - 1979.34] um and it talks very extensively about

[1974.96 - 1982.82] the political social economic and

[1979.34 - 1986.1789999999999] religious uh reasons behind our cultural

[1982.82 - 1988.84] workaholism as a culture we use fear

[1986.179 - 1992.98] guilt and shame to keep people working

[1988.84 - 1997.1] and we also uh use fear guilt and shame

[1992.98 - 2000.159] around laziness or idleness which means

[1997.1 - 2003.1] that it has been the established policy

[2000.159 - 2005.3200000000002] uh of of state and federal governments

[2003.1 - 2007.36] that people ought to be working and we

[2005.32 - 2010.48] ought to incentivize that behavior which

[2007.36 - 2012.6999999999998] means that um the the that mentality

[2010.48 - 2014.6200000000001] trickles down and it is implicitly

[2012.7 - 2017.019] embedded in all of our legislation all

[2014.62 - 2019.2399999999998] of our fiscal policy all of our monetary

[2017.019 - 2021.76] policy and then also gets embedded in

[2019.24 - 2023.919] the Zeitgeist of our culture where we

[2021.76 - 2025.779] have uh you know the hustle culture that

[2023.919 - 2028.0] is one of the one of the primary ways

[2025.779 - 2029.5] that you see it today is like if you're

[2028.0 - 2031.659] not working two or three jobs you're

[2029.5 - 2033.039] falling behind that is people who have

[2031.659 - 2035.159] internalized

[2033.039 - 2038.32] capitalism

[2035.159 - 2040.8400000000001] and then you end up with whenever anyone

[2038.32 - 2043.4189999999999] pushes back you say well who who are you

[2040.84 - 2044.86] to declare what's good or bad why why do

[2043.419 - 2047.44] you get to say that this is not good or

[2044.86 - 2049.48] bad Society has decided that laziness is

[2047.44 - 2050.679] bad

[2049.48 - 2052.72] so

[2050.679 - 2055.78] what we need instead instead of this

[2052.72 - 2057.52] hyper-competitive mentality is we need a

[2055.78 - 2059.139] post-scarcity and hyperabundance

[2057.52 - 2061.96] mentality which is a completely

[2059.139 - 2064.54] different mentality from laziness as a

[2061.96 - 2067.419] sin to you must be working or otherwise

[2064.54 - 2069.58] you're going to be condemned right so

[2067.419 - 2071.56] post scarcity is a hypothetical state

[2069.58 - 2074.02] where the scarcity of all basic goods

[2071.56 - 2075.639] and services uh practically no longer

[2074.02 - 2077.32] exists

[2075.639 - 2079.2400000000002] um and hyperabundance is another way

[2077.32 - 2081.28] it's uh two sides of the same coin

[2079.24 - 2083.5] stopper abundance is just another way of

[2081.28 - 2085.8390000000004] thinking about post-scarcity air and

[2083.5 - 2087.94] sunlight are hyper abundant resources

[2085.839 - 2089.56] air is so abundant that you never have

[2087.94 - 2091.3] to pay for it all you have to do is

[2089.56 - 2093.399] regulate it so to keep it clean enough

[2091.3 - 2096.04] so that everyone can use it

[2093.399 - 2097.66] sunlight is also hyper abundant because

[2096.04 - 2099.52] again you don't need to pay for it

[2097.66 - 2102.22] unless you're like at the North Pole

[2099.52 - 2103.66] where you have like Perpetual night for

[2102.22 - 2106.18] three months

[2103.66 - 2108.8199999999997] um so with massive increases in human

[2106.18 - 2112.24] efficiency why don't we have a post

[2108.82 - 2116.619] scarcity and Hyper abundant mentality

[2112.24 - 2118.66] um so one or I guess I I phrased that

[2116.619 - 2120.82] wrong we don't redistribute the benefits

[2118.66 - 2122.74] of offensive of our efficiency because

[2120.82 - 2124.0] we don't have those mentalities we'll

[2122.74 - 2126.52] get into how do we adopt those

[2124.0 - 2128.92] mentalities soon but

[2126.52 - 2130.98] it all basically comes down to beliefs

[2128.92 - 2134.56] economists have certain beliefs

[2130.98 - 2137.02] politicians have certain beliefs uh the

[2134.56 - 2139.599] the the philosophical Zeitgeist of the

[2137.02 - 2142.24] time gives us certain beliefs but

[2139.599 - 2144.579] beliefs are they're often anchored in

[2142.24 - 2146.74] some evidence uh but beliefs are also

[2144.579 - 2148.119] often arbitrary which is why I picked

[2146.74 - 2149.9199999999996] this graphic is just because it's like

[2148.119 - 2152.02] you you pray at the altar of

[2149.92 - 2154.1800000000003] neoliberalism or you pray at The Shrine

[2152.02 - 2156.7] of of capitalism and corporatism or

[2154.18 - 2159.359] whatever like whatever your preferred uh

[2156.7 - 2159.359] philosophy is

[2159.46 - 2164.079] um so how does that physically manifest

[2161.74 - 2166.72] right okay I can talk about you know

[2164.079 - 2169.2400000000002] Zeitgeist and philosophy and beliefs and

[2166.72 - 2171.8199999999997] however I want but the the the the the

[2169.24 - 2173.2] the the bottom line is

[2171.82 - 2176.2000000000003] in

[2173.2 - 2178.5989999999997] after after the after World War II which

[2176.2 - 2180.8799999999997] so the the marginal tax rates were

[2178.599 - 2182.5] really high to pay off the war debt so

[2180.88 - 2184.1800000000003] it makes sense that after the war debt

[2182.5 - 2187.66] is paid off tax rates go down a little

[2184.18 - 2190.3799999999997] bit but then they just kept cratering so

[2187.66 - 2193.66] what happened well around 1980

[2190.38 - 2196.359] neoliberalism became the de facto uh

[2193.66 - 2198.46] policy globally and that was uh pushed

[2196.359 - 2200.68] by Margaret Thatcher and Ronald Reagan

[2198.46 - 2202.7200000000003] which you know two of the most powerful

[2200.68 - 2205.359] economies in the world we set the tone

[2202.72 - 2207.3999999999996] for everyone else it was also adopted by

[2205.359 - 2210.94] the IMF and the World Bank

[2207.4 - 2212.5] so with the rise of neoliberalism the

[2210.94 - 2215.619] belief was

[2212.5 - 2217.599] um you you deregulate you privatize you

[2215.619 - 2218.6800000000003] give people individual liberty so that

[2217.599 - 2220.54] they can do whatever they want with

[2218.68 - 2223.18] their money and the government should do

[2220.54 - 2225.4] less now there were some really

[2223.18 - 2226.96] compelling reasons for the adoption of

[2225.4 - 2229.54] neoliberalism because what was working

[2226.96 - 2231.94] what we had before then was working even

[2229.54 - 2233.56] worse in some respects there's a book

[2231.94 - 2236.02] called A Brief History of neoliberalism

[2233.56 - 2237.88] by David Harvey definitely recommend it

[2236.02 - 2240.88] because it does geneoliberalism a fair

[2237.88 - 2243.339] Shake but it also points out its flaws

[2240.88 - 2245.6800000000003] in reasoning and logic and also just

[2243.339 - 2247.32] where it completely goes off the rails

[2245.68 - 2250.1189999999997] point being is

[2247.32 - 2251.7400000000002] neoliberalism is the reason that we are

[2250.119 - 2253.119] experi is one of the reasons we're

[2251.74 - 2255.7599999999998] experiencing what we are experiencing

[2253.119 - 2258.339] today uh population growth and globalism

[2255.76 - 2259.9] are also reasons and there is a huge

[2258.339 - 2261.2799999999997] backlash against globalism right now

[2259.9 - 2264.52] which is very interesting to watch it

[2261.28 - 2267.82] play out but tax rates are just one way

[2264.52 - 2270.22] that you can tell that uh we have this

[2267.82 - 2272.92] this different mentality that goes away

[2270.22 - 2275.0789999999997] from uh or that it that is further from

[2272.92 - 2279.04] post scarcity and hyperabundance and

[2275.079 - 2281.8] that is I got mine screw you

[2279.04 - 2284.2599999999998] okay so what Drive is this I'm glad you

[2281.8 - 2286.2000000000003] asked nihilism nihilism is the

[2284.26 - 2288.579] underpinning philosophy behind all of us

[2286.2 - 2291.16] neoliberalism is an impure is is an

[2288.579 - 2294.2200000000003] intrinsically nihilistic philosophy

[2291.16 - 2298.54] um it also a dystopian philosophy so in

[2294.22 - 2299.74] the uh 19th century uh in Russia of

[2298.54 - 2301.7799999999997] course Russia

[2299.74 - 2303.9399999999996] um the nihilists said nothing matters

[2301.78 - 2305.26] and they were basically anarchists they

[2303.94 - 2308.619] wanted to burn everything down and start

[2305.26 - 2310.3] over the idea is spread Westward

[2308.619 - 2311.6800000000003] um and it really caught on you might

[2310.3 - 2313.3] have heard about this dude named uh

[2311.68 - 2315.2799999999997] Frederick Nietzsche

[2313.3 - 2317.7400000000002] um so he wrote extensively about

[2315.28 - 2320.02] nihilism and the will to power and

[2317.74 - 2322.2999999999997] basically invented rugged individualism

[2320.02 - 2323.68] and a whole bunch of toxic stuff all in

[2322.3 - 2328.2400000000002] one go

[2323.68 - 2331.56] um so as we were challenging our beliefs

[2328.24 - 2333.9399999999996] around religion spirituality philosophy

[2331.56 - 2335.619] nihilism takes over because it's like uh

[2333.94 - 2337.42] we can't figure out anything so just

[2335.619 - 2339.6400000000003] nothing matters there's physical

[2337.42 - 2341.5] evidence that that God exists that

[2339.64 - 2343.72] anyone cares about us nothing matters

[2341.5 - 2346.3] and the capitalist stuff stepped in and

[2343.72 - 2348.16] said well my prophets matter

[2346.3 - 2350.5600000000004] and so

[2348.16 - 2353.02] then everyone else was like all right

[2350.56 - 2356.44] sure fine profits matter

[2353.02 - 2358.48] uh and then now as a as a planet we

[2356.44 - 2360.64] optimize for GDP

[2358.48 - 2363.04] does that sound like how we want to live

[2360.64 - 2364.66] like the the the single number that

[2363.04 - 2367.06] everyone spends all kinds of time

[2364.66 - 2368.64] focusing on is GDP

[2367.06 - 2372.22] gross domestic product

[2368.64 - 2373.96] right so we've optimized for GDP we're

[2372.22 - 2375.52] not optimized for life we're not

[2373.96 - 2377.859] optimizing for Humanity we're not

[2375.52 - 2379.18] optimizing for anything else other than

[2377.859 - 2381.339] product

[2379.18 - 2383.2] so a century later

[2381.339 - 2384.82] how do we feel about that

[2383.2 - 2386.7999999999997] did it work

[2384.82 - 2388.1800000000003] we're more productive than ever but are

[2386.8 - 2391.119] we happier than ever

[2388.18 - 2394.18] all metrics indicate that happiness is

[2391.119 - 2395.92] cratered that we are the like in one of

[2394.18 - 2398.44] the most unhappy times

[2395.92 - 2400.54] in recorded history

[2398.44 - 2402.64] um and the reason is because we have

[2400.54 - 2404.98] this undercurrent of nihilism that says

[2402.64 - 2406.359] you don't matter I don't matter and then

[2404.98 - 2409.06] someone else comes in and fills in a

[2406.359 - 2411.339] narrative that says well prophets matter

[2409.06 - 2413.32] we saw this in memes at the beginning of

[2411.339 - 2415.2999999999997] the pandemic where everyone was

[2413.32 - 2416.98] panicking they're like but the economy

[2415.3 - 2419.02] and everyone's like I don't care about

[2416.98 - 2421.54] your economy dude like I'm gonna go die

[2419.02 - 2425.14] like don't tell me to reopen the economy

[2421.54 - 2427.359] and so that's when the uh the the

[2425.14 - 2428.2599999999998] cartoonishness of the Ferengi from Star

[2427.359 - 2431.68] Trek

[2428.26 - 2433.6600000000003] kind of became a little too real and

[2431.68 - 2437.2] that's why I picked uh picked Quark here

[2433.66 - 2439.66] to represent this because the Ferengi

[2437.2 - 2441.9399999999996] um which were invented in the late 80s I

[2439.66 - 2444.8199999999997] believe in first Star Trek

[2441.94 - 2447.4] um where a caricature of our own

[2444.82 - 2449.44] fixation on profits and in fact the

[2447.4 - 2451.6600000000003] ferangi Constitution says nothing about

[2449.44 - 2453.7000000000003] morality it only says about Prophets The

[2451.66 - 2455.859] Frankie constitution is called the rules

[2453.7 - 2458.68] of acquisition that is their highest

[2455.859 - 2460.619] religious and and philosophical Doctrine

[2458.68 - 2463.0] and

[2460.619 - 2464.859] uh let's just say it seems like it was a

[2463.0 - 2466.3] little too on point

[2464.859 - 2469.0] um so

[2466.3 - 2470.92] if nihilism is the problem nihilism is

[2469.0 - 2472.3] the underlying problem that says nothing

[2470.92 - 2473.7400000000002] matters I'm just going to look it out

[2472.3 - 2476.8] for myself

[2473.74 - 2478.1189999999997] the answer then is post nihilism

[2476.8 - 2479.619] so

[2478.119 - 2483.28] some people

[2479.619 - 2485.859] like Jordan Peterson Eugene rose and a

[2483.28 - 2488.32] few others have all said we need to go

[2485.859 - 2490.2] backwards we need to go back to

[2488.32 - 2492.6400000000003] traditional structures

[2490.2 - 2493.359] uh and their hearts are in the right

[2492.64 - 2496.24] place

[2493.359 - 2497.859] but Humanity never goes backwards

[2496.24 - 2499.72] and look I mean there might be fits and

[2497.859 - 2502.42] starts there might be temporary setbacks

[2499.72 - 2505.359] setbacks like you know we we struck down

[2502.42 - 2508.1800000000003] OV Wade so that's a setback but in the

[2505.359 - 2511.18] grand scheme of things we go forwards so

[2508.18 - 2513.94] rather than being an anti-nihilist

[2511.18 - 2516.2799999999997] rather than being a humanist rather than

[2513.94 - 2518.56] trying to go backwards and force things

[2516.28 - 2522.099] into you know oh let's just go back to

[2518.56 - 2524.5789999999997] the good old days now my recommendation

[2522.099 - 2528.1600000000003] is that we move forward we move through

[2524.579 - 2530.079] nihilism we embrace it we say yes there

[2528.16 - 2531.8199999999997] is some Merit here but it is

[2530.079 - 2533.7400000000002] insufficient this is what happened with

[2531.82 - 2537.099] modernism and post-modernism

[2533.74 - 2540.339] modernism said that there should be that

[2537.099 - 2542.8] Universal truths should be uh found

[2540.339 - 2544.7799999999997] through science and reason and

[2542.8 - 2546.82] experience but then as we became more

[2544.78 - 2548.5600000000004] globally aware we realized actually it's

[2546.82 - 2550.2400000000002] really hard to establish universal truth

[2548.56 - 2552.4] let's throw out that idea and post

[2550.24 - 2554.02] post-modernism said there is no such

[2552.4 - 2555.52] thing as universal truth it's all

[2554.02 - 2558.52] relative

[2555.52 - 2561.04] nihilism tried to say nothing matters

[2558.52 - 2564.52] and that is really one it's really

[2561.04 - 2567.339] immature two it's premature

[2564.52 - 2570.7599999999998] and three it's just deeply unsatisfying

[2567.339 - 2572.38] right like if you if you say nothing

[2570.76 - 2574.96] matters

[2572.38 - 2577.839] like are you not paying attention to the

[2574.96 - 2579.819] fact that like life is incredibly rare

[2577.839 - 2583.0] so the central tenet of post-nihilism

[2579.819 - 2586.06] that I propose is is that we say that

[2583.0 - 2588.099] all life is intrinsically valuable

[2586.06 - 2590.14] and that this is not a rejection of

[2588.099 - 2592.1800000000003] nihilism this is not anti-nihilism this

[2590.14 - 2594.64] is moving forward and says actually we

[2592.18 - 2598.2999999999997] got to the ground truth we we we we

[2594.64 - 2602.02] questioned what does anything mean

[2598.3 - 2604.0] and we exist like I am awake I am a bit

[2602.02 - 2605.92] of matter and energy that is aware of

[2604.0 - 2607.18] its own existence and when you stop to

[2605.92 - 2608.26] think about that that's pretty freaking

[2607.18 - 2610.8999999999996] cool

[2608.26 - 2612.1600000000003] right like just hold on to that for a

[2610.9 - 2613.54] minute

[2612.16 - 2616.72] why

[2613.54 - 2618.7599999999998] why is it that what separates you know

[2616.72 - 2620.859] some some organic matter from the rest

[2618.76 - 2622.0600000000004] of the universe we are extraordinarily

[2620.859 - 2624.64] rare

[2622.06 - 2626.2] and by we I mean all living things we

[2624.64 - 2628.3799999999997] are rare and that makes us really

[2626.2 - 2628.3799999999997] special

[2628.599 - 2631.7200000000003] so if we all agree that life is pretty

[2630.52 - 2633.579] cool

[2631.72 - 2636.7599999999998] where can we go from there

[2633.579 - 2638.6800000000003] what if we say like life is cool life is

[2636.76 - 2641.38] special we are special just by virtue of

[2638.68 - 2644.7999999999997] existing one of the things that I think

[2641.38 - 2647.02] you can you can derive from that is that

[2644.8 - 2649.599] we all deserve to feel it we didn't ask

[2647.02 - 2651.52] to be here no one can ask to be born in

[2649.599 - 2653.8590000000004] fact there's anti-natalism that's a

[2651.52 - 2657.099] philosophical uh disposition that says

[2653.859 - 2659.98] that assigns a negative value to birth

[2657.099 - 2661.96] and that antinatalism is a perfectly

[2659.98 - 2664.72] reasonable reaction to growing up in a

[2661.96 - 2666.819] nihilistic World it says hey you created

[2664.72 - 2668.5] me and now you don't care about me

[2666.819 - 2671.2] of course I don't want to be here this

[2668.5 - 2672.04] is this is stupid but what if instead we

[2671.2 - 2674.68] say

[2672.04 - 2678.42] all life is intrinsically valuable and

[2674.68 - 2678.4199999999996] therefore we all deserve to feel good

[2678.579 - 2682.96] and of course I can hear the

[2680.8 - 2685.6600000000003] internalized nihilism speaking not just

[2682.96 - 2688.359] in in my audience but in myself

[2685.66 - 2690.64] who said that anyone deserves anything

[2688.359 - 2692.859] and what I mentioned earlier about the

[2690.64 - 2695.2599999999998] arbitrariness of beliefs

[2692.859 - 2698.92] when you when you really boil it down

[2695.26 - 2700.0] all beliefs are one personal and

[2698.92 - 2701.7400000000002] subjective

[2700.0 - 2703.78] and everything is a belief whether it's

[2701.74 - 2705.8799999999997] your belief in science or your belief in

[2703.78 - 2707.6800000000003] religion or whatever you believe

[2705.88 - 2710.26] and it's shored up by some evidence

[2707.68 - 2711.46] right so we believe in science because

[2710.26 - 2713.5] of evidence there are plenty of people

[2711.46 - 2715.26] that believe in various religions based

[2713.5 - 2718.66] on their own their own personal evidence

[2715.26 - 2720.2200000000003] right there is social evidence there is

[2718.66 - 2722.319] empirical evidence there's scientific

[2720.22 - 2724.319] evidence whatever I'm about to go on

[2722.319 - 2727.18] that rant that Picard did like

[2724.319 - 2728.619] the first duty of Starfleet officers to

[2727.18 - 2730.839] the truth whether it's personal truth

[2728.619 - 2733.6600000000003] historical truth scientific truth

[2730.839 - 2736.2999999999997] spiritual truth whatever truth means to

[2733.66 - 2737.859] you it is personal it is intrinsically

[2736.3 - 2740.7400000000002] personal this is something that I took

[2737.859 - 2743.98] from post-modernism yes I agree with

[2740.74 - 2745.72] that but we because beliefs are

[2743.98 - 2747.76] arbitrary we all just say you know we're

[2745.72 - 2750.3999999999996] done with nihilism let's move beyond

[2747.76 - 2751.599] that let's go to something different and

[2750.4 - 2754.1800000000003] more

[2751.599 - 2757.3] and uh you know this could be us but we

[2754.18 - 2759.339] let the nihilism worms in our brain

[2757.3 - 2761.319] Okay so

[2759.339 - 2763.7799999999997] stepping away from religion and

[2761.319 - 2766.839] spirituality for a second

[2763.78 - 2769.2400000000002] empirically speaking how do we how do we

[2766.839 - 2771.7599999999998] move towards a more post-nihilistic

[2769.24 - 2774.0989999999997] world what does that look like well

[2771.76 - 2776.6800000000003] if Ai and automation are going to

[2774.099 - 2778.78] destroy 50 plus percent of jobs in the

[2776.68 - 2781.24] next 10 years uh we're going to need a

[2778.78 - 2782.8590000000004] grain Dole and for historical reference

[2781.24 - 2786.4599999999996] for people that aren't history nerds

[2782.859 - 2788.14] Rome ancient Rome had a grain dull when

[2786.46 - 2790.0] times got tough where they just gave out

[2788.14 - 2791.02] grain for free because nobody could

[2790.0 - 2794.38] afford it

[2791.02 - 2795.099] but all the wealthy Barons they produced

[2794.38 - 2798.88] enough

[2795.099 - 2801.099] and so redistribution is nothing new

[2798.88 - 2803.2000000000003] uh nihilism made us complacent and

[2801.099 - 2804.819] expect dystopian outcomes but if we

[2803.2 - 2805.72] change our minds if we all change our

[2804.819 - 2807.16] minds

[2805.72 - 2809.2599999999998] then we can agree that maybe

[2807.16 - 2811.1189999999997] redistribution it's time for this idea

[2809.26 - 2813.1600000000003] again

[2811.119 - 2814.839] it won't happen yet because we all still

[2813.16 - 2818.02] have that crab mentality that that that

[2814.839 - 2820.42] fear guilt and shame around scarcity so

[2818.02 - 2823.3] another way of saying crab mentality is

[2820.42 - 2826.2400000000002] scarcity mentality scarcity mindset so

[2823.3 - 2829.3590000000004] we need to get over our scarcity mindset

[2826.24 - 2831.7] and post nihilism the reason I say post

[2829.359 - 2834.16] nihilism is the answer is because it

[2831.7 - 2836.02] changes our orientation not just towards

[2834.16 - 2838.96] each other but towards ourselves

[2836.02 - 2840.7599999999998] one of the reasons that I quit my job my

[2838.96 - 2844.599] day job is because I realized I deserve

[2840.76 - 2846.1600000000003] to feel better than how they treated me

[2844.599 - 2849.28] and I think everyone deserves to feel

[2846.16 - 2852.22] better and when I when I discovered that

[2849.28 - 2854.8] it was an eye-opening it was like a

[2852.22 - 2856.2999999999997] major Awakening of weight I deserve to

[2854.8 - 2857.6800000000003] feel better everyone deserves to feel

[2856.3 - 2859.9] better

[2857.68 - 2861.5789999999997] um and then I was like yeah this is I

[2859.9 - 2863.5] feel like this is a universal principle

[2861.579 - 2865.6600000000003] and if we all believe that everyone

[2863.5 - 2868.3] deserves to feel better our orientation

[2865.66 - 2870.94] towards scarcity changes

[2868.3 - 2872.38] I went shopping I was when I was sick I

[2870.94 - 2875.38] went to the grocery store to get soup

[2872.38 - 2878.44] with my fiance and uh there was a guy

[2875.38 - 2879.579] outside asking for change and I don't

[2878.44 - 2881.44] carry cash

[2879.579 - 2882.94] and I said sorry man I don't I don't

[2881.44 - 2885.28] have any cash and I thought about it I

[2882.94 - 2888.339] was like wait I got a bag full of food

[2885.28 - 2890.1400000000003] like let me just give him some food

[2888.339 - 2891.52] um and I I walked back and I said hey

[2890.14 - 2892.6189999999997] man I don't have any cash but you want

[2891.52 - 2895.06] some soup

[2892.619 - 2896.92] you know like I was I was actively sick

[2895.06 - 2898.48] and I'm like I've got more than I need

[2896.92 - 2901.1800000000003] like

[2898.48 - 2903.359] I think that he deserves to feel good

[2901.18 - 2905.74] just by virtue he exists I don't care

[2903.359 - 2907.7] what his history is

[2905.74 - 2909.339] sorry I'm getting choked up

[2907.7 - 2911.319] [Music]

[2909.339 - 2914.98] I don't care

[2911.319 - 2918.339] what someone has been through or done

[2914.98 - 2919.839] if if we're here if we exist we all

[2918.339 - 2922.38] deserve to feel good

[2919.839 - 2922.38] sorry

[2924.579 - 2930.88] so it's about striking a balance right

[2927.28 - 2933.099] obviously this is a really big idea you

[2930.88 - 2937.06] know Mass distribution

[2933.099 - 2939.6400000000003] Marxism and socialism isn't the answer

[2937.06 - 2941.2599999999998] um it's too radical I don't think that

[2939.64 - 2944.02] centralized ownership the collective

[2941.26 - 2945.6400000000003] ownership and and centralized control is

[2944.02 - 2947.98] the answer

[2945.64 - 2950.2] um because you know the so-called

[2947.98 - 2951.7] experts often get it wrong look up the

[2950.2 - 2953.0789999999997] famines that happen in a Soviet Union

[2951.7 - 2955.54] because of the so-called experts

[2953.079 - 2957.3390000000004] deciding what to do with the Farms

[2955.54 - 2960.7] um so yeah like we should be we should

[2957.339 - 2963.5789999999997] be wary of centralized ownership we need

[2960.7 - 2965.5] to bank on the wisdom of masses

[2963.579 - 2968.1400000000003] um which which says okay we need we do

[2965.5 - 2970.3] need we need to we that we do need some

[2968.14 - 2972.0989999999997] level of Liberty and individual decision

[2970.3 - 2974.079] and also collective decision making not

[2972.099 - 2977.56] Collective ownership collective decision

[2974.079 - 2980.619] making Which democracy is Republic's

[2977.56 - 2982.72] representative democracy is a method of

[2980.619 - 2985.9] collective decision making

[2982.72 - 2987.9399999999996] neither is libertarianism or Anarchy a

[2985.9 - 2989.98] solution sorry

[2987.94 - 2991.66] um we do need structure

[2989.98 - 2994.18] when you've got a planet with eight

[2991.66 - 2996.04] billion people on it you absolutely need

[2994.18 - 2997.8999999999996] you need power structures now those

[2996.04 - 2999.7599999999998] power structures need to be fair they

[2997.9 - 3003.0] need to be better

[2999.76 - 3004.5] now I think we can probably all agree I

[3003.0 - 3005.4] don't want to speak for everyone but I

[3004.5 - 3007.44] think

[3005.4 - 3008.46] we can agree that individual liberty is

[3007.44 - 3011.2200000000003] important

[3008.46 - 3012.599] I like being able to decide where I'm

[3011.22 - 3014.8799999999997] going to work who I'm going to live with

[3012.599 - 3018.54] who I spend time with what I do for fun

[3014.88 - 3020.4] what I believe what I think

[3018.54 - 3022.619] so if we can all agree that individual

[3020.4 - 3025.26] liberty is is good then it's like okay

[3022.619 - 3027.2400000000002] well we don't want any hard hard left or

[3025.26 - 3028.3190000000004] hard right we need to be you know a

[3027.24 - 3031.14] little bit more reasonable a little bit

[3028.319 - 3034.68] more modern moderate sorry

[3031.14 - 3036.839] by extension I think we can agree that

[3034.68 - 3038.819] property rights are important and what I

[3036.839 - 3041.16] mean by that is I own my house my house

[3038.819 - 3043.619] wasn't given to me by the government I

[3041.16 - 3046.0789999999997] worked and I earned my house and so like

[3043.619 - 3048.1800000000003] it's a reward right

[3046.079 - 3050.3390000000004] um our brains are efficiency calculators

[3048.18 - 3052.9199999999996] and it's like okay well what am I if

[3050.339 - 3055.44] there's no reward then why am I gonna do

[3052.92 - 3057.48] it now this is where like okay as much

[3055.44 - 3059.099] as I wish that it was it was like this

[3057.48 - 3061.68] like Star Trek

[3059.099 - 3063.0] um you know says like we all work to uh

[3061.68 - 3064.98] for the betterment of ourselves and

[3063.0 - 3067.38] Mankind to be fair that's when I started

[3064.98 - 3069.119] that's why I started my Youtube video

[3067.38 - 3070.619] um was I just wanted to get information

[3069.119 - 3072.2400000000002] out there

[3070.619 - 3074.88] um but the reward is still like social

[3072.24 - 3077.04] validation right was like I'm doing this

[3074.88 - 3080.52] because I'm part of a society

[3077.04 - 3081.96] so anyways going down to tangent point

[3080.52 - 3083.28] being is that property rights are

[3081.96 - 3085.319] important

[3083.28 - 3087.059] so if individual liberty is important

[3085.319 - 3089.64] and property rights are important but

[3087.059 - 3091.8] also fairness and Equity is important my

[3089.64 - 3094.74] answer is we should go for a

[3091.8 - 3096.6600000000003] well-regulated economy keep it fair

[3094.74 - 3098.3999999999996] with robust redistribution that's the

[3096.66 - 3100.5] grain Dole idea

[3098.4 - 3102.6600000000003] so this idea still has to be paired with

[3100.5 - 3105.24] that new philosophy because our

[3102.66 - 3107.3999999999996] philosophy of scarcity mentality our

[3105.24 - 3111.0] scarcity of nihilism won't let us do

[3107.4 - 3113.46] that we need a new moral framework or a

[3111.0 - 3115.14] new disposition towards not just each

[3113.46 - 3118.14] other but towards ourselves

[3115.14 - 3120.66] in order to achieve this

[3118.14 - 3125.18] so thank you all for watching be kind

[3120.66 - 3125.18] it's already hard enough take care